@misc{,
   abstract = {Belief networks are directed acyclic graphs in which the nodes represent propositions (or variables), the arcs signify direct dependencies between the linked propositions, and the strengths of these dependencies are quantified by conditional probabilities. A network of this sort can be used to represent the generic knowledge of a domain expert, and it turns into a computational architecture if the links are used not merely for storing factual knowledge but also for directing and activating the data flow in the computations which manipulate this knowledge. The first part of the paper deals with the task of fusing and propagating the impacts of new information through the networks in such a way that, when equilibrium is reached, each proposition will be assigned a measure of belief consistent with the axioms of probability theory. It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network. The second part of the paper deals with the problem of finding a tree-structured representation for a collection of probabilistically coupled propositions using auxiliary (dummy) variables, colloquially called "hidden causes." It is shown that if such a tree-structured representation exists, then it is possible to uniquely uncover the topology of the tree by observing pairwise dependencies among the available propositions (i.e., the leaves of the tree). The entire tree structure, including the strengths of all internal relationships, can be reconstructed in time proportional to n log n, where n is the number of leaves.},
   author = {Judea Pearl},
   title = {Fusion, Propagation, and Structuring in Belief Networks*},
}
@misc{Banerjee2008,
   abstract = {We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added 1-norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our first algorithm uses block coordinate descent, and can be interpreted as recursive 1-norm penalized regression. Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright and Jordan, 2006), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data.},
   author = {Onureena Banerjee and Laurent El Ghaoui and Aspremon@princeton Edu},
   journal = {Journal of Machine Learning Research},
   keywords = {Gaussian graphical model,binary data,convex optimization,maximum likelihood estimation,model selection},
   pages = {485-516},
   title = {Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data Alexandre d'Aspremont},
   volume = {9},
   year = {2008},
}
@article{Yang2013,
   abstract = {Travel demand forecasting is subject to great uncertainties. A systematic uncertainty analysis can provide insights into the level of confidence on the model outputs, and also identify critical sources of uncertainty for enhancing the robustness of the travel demand model. In this paper, we develop a systematic framework for quantitative uncertainty analysis of a combined travel demand model (CTDM) using the analytical sensitivity-based method. The CTDM overcomes limitations of the sequential four-step procedure since it is based on a single unifying rationale. The analytical sensitivity-based method requires less computational effort than the sampling-based method. Meanwhile, the uncertainties stemming from inputs and parameters can be treated separately so that the individual and collective effects of uncertainty on the outputs can be clearly assessed and quantified. Numerical examples are finally used to demonstrate the proposed sensitivity-based uncertainty analysis method for the CTDM. © 2013.},
   author = {Chao Yang and Anthony Chen and Xiangdong Xu and S. C. Wong},
   doi = {10.1016/j.trb.2013.07.006},
   issn = {01912615},
   journal = {Transportation Research Part B: Methodological},
   keywords = {Combined travel demand model,Nonlinear program,Sensitivity analysis,Uncertainty analysis},
   pages = {225-244},
   publisher = {Elsevier Ltd},
   title = {Sensitivity-based uncertainty analysis of a combined travel demand model},
   volume = {57},
   year = {2013},
}
@misc{,
   keywords = {activity model,data assimilation,mobile spatial statistics},
   title = {東京都市圏における アクティビティシミュレーションと 観測データの融合手法},
}
@article{Chiesa2022,
   abstract = {Traffic and transportation forecasting is a key issue in urban planning aimed to provide a greener and more sustainable environment to residents. Their privacy is a second key issue that requires synthetic travel data. A possible solution is offered by generative models. Here, a variational autoencoder architecture has been trained on a floating car dataset in order to grasp the statistical features of the traffic demand in the city of Rome. The architecture is based on multilayer dense neural networks for encoding and decoding parts. A brief analysis of parameter influence is conducted. The generated trajectories are compared with those in the dataset. The resulting reconstructed synthetic data are employed to compute the traffic fluxes and geographic distribution of parked cars. Further work directions are provided.},
   author = {Stefano Chiesa and Sergio Taraglio},
   doi = {10.3390/computers11050071},
   issn = {2073431X},
   issue = {5},
   journal = {Computers},
   keywords = {generative models,traffic model,urban mobility,variational autoencoder},
   month = {5},
   publisher = {MDPI},
   title = {Traffic Request Generation through a Variational Auto Encoder Approach},
   volume = {11},
   year = {2022},
}
@article{Chiesa2022,
   abstract = {Traffic and transportation forecasting is a key issue in urban planning aimed to provide a greener and more sustainable environment to residents. Their privacy is a second key issue that requires synthetic travel data. A possible solution is offered by generative models. Here, a variational autoencoder architecture has been trained on a floating car dataset in order to grasp the statistical features of the traffic demand in the city of Rome. The architecture is based on multilayer dense neural networks for encoding and decoding parts. A brief analysis of parameter influence is conducted. The generated trajectories are compared with those in the dataset. The resulting reconstructed synthetic data are employed to compute the traffic fluxes and geographic distribution of parked cars. Further work directions are provided.},
   author = {Stefano Chiesa and Sergio Taraglio},
   doi = {10.3390/computers11050071},
   issn = {2073431X},
   issue = {5},
   journal = {Computers},
   keywords = {generative models,traffic model,urban mobility,variational autoencoder},
   month = {5},
   publisher = {MDPI},
   title = {Traffic Request Generation through a Variational Auto Encoder Approach},
   volume = {11},
   year = {2022},
}
@article{Pereira2022,
   abstract = {In this study, an activity-based travel demand model of the Ústí nad Labem district (Czech Republic) is created. To do this, an advanced travel demand synthesis process is presented by utilizing the Eqasim framework, which is a pipeline-processing, initial raw data to simulation step. The framework is extensively modified and extended with several algorithms in order to utilize multiple data points for increasing realism in mobility for travel demand models. Two major extensions are provided. First, the pipeline framework is improved to estimate inbound and outbound trips of the study area, comprising a main city and 23 surrounding municipalities. The extended framework assigns synthetic gates for the study area as hubs for the inclusion of inbound and outbound trips. Second, the pipeline framework is advanced to provide a more compatible match of travel destination and activity location state. To do this, the extended framework assigns a capacity for each facility identified for the study area, the expected number of visitors to each facility, and the number of residents in each building. The resulting demand model is presented and the generated trips are evaluated based on locational, transport mode, and sociodemographic characteristics with origin–destination (OD) bundling. Additionally, distribution analyses of the present model are conducted to understand the matching results on a detailed level. The results demonstrate that the present model provides a reasonable output for transport researchers when testing different mobility scenarios and the provided extensions helps them to reduce implausible reflections of the distribution of travel and activity characteristics in household travel surveys while creating demand models, thus increasing realism. Lastly, open-source playground and code repository for further future improvement of synthetic travel synthesis methods are created, which enhances a deep understanding of the preparatory and methodological backgrounds required for complex activity-based simulations in order to inspire transport planners.},
   author = {André Maia Pereira and Ali Enes Dingil and Ondřej Přibyl and Vojtěch Myška and Jakub Vorel and Milan Kříž},
   doi = {10.3390/app121910032},
   issn = {20763417},
   issue = {19},
   journal = {Applied Sciences (Switzerland)},
   keywords = {MATSim model,activity-based approach,statistical matching,synthetic population,travel demand},
   month = {10},
   publisher = {MDPI},
   title = {An Advanced Travel Demand Synthesis Process for Creating a MATSim Activity Model: The Case of Ústí nad Labem},
   volume = {12},
   year = {2022},
}
@misc{Schweizer2018,
   abstract = {This article explains a travel demand generator developed within the SUMOPy framework which aims at providing person-based plans for the SUMO micro-simulator. The plan generation has four principal steps: 1.) a population needs to be generated, with specific attributes for each person; 2.) activities and their associated locations need to be identified, 3.) travel plans need to be generated, with the aim to connect the various activities in an efficient manner. 4.) A microsimulator determines the effective travel times for each plan which persons can use to modify or change their plan. In a first part, this article briefly describes other software packages which allow activity based demand models. It is further explained that the use of SUMO as microsimulator is particularly suited to evaluate multi-modal travel plans. The article then focuses on SUMOPy's activity based demand model and in particular on the population synthesizer, plan generation and plan selection step. SUMOPy's activity based demand framework has two distinguishing features: 1.) the time travel budget can be controlled during the population synthesizing process; 2.) The concept of abstract mobility strategies-each person may have different feasible plans, following different mobility strategies. The SUMO micro-simulator is used to evaluate the effective travel time of plans for the entire population. Regarding the plan selection method, a method is described if and how persons change plans based on the the effective travel times experienced after each simulation run. It is shown by means of a synthetic network and a realistic city network that the proposed algorithm is converging and total travel times are decreasing after each simulation run until an equilibrium is reached. Some preliminary attempts were undertaken to improve the speed of convergence. For both of the analyzed networks an equilibrium has been reached after approximately 10 simulation runs.},
   author = {J Schweizer and F Rupi and F Filippi and C Poliziani},
   title = {Engineering EPiC Series in Engineering Generating activity based, multi-modal travel demand for SUMO},
   volume = {2},
   year = {2018},
}
@misc{Gong2023,
   abstract = {Human motivations are an important factor in influencing human movement. However, most existing studies on passenger travel demand prediction focus on external characteristics of movement, but neglect the influence of activities and the motivations behind them, on the citizen's trip decisions. In this study, we proposed an agent-based model, to predict passengers’ travel behaviour over a period of time, particularly when the urban structure changes. The model includes passenger characteristics, transitions in travel demands between activities over time, and their movement in space and time. In addition, we innovatively calibrated the agent-based model locally using Geographically Weighted Regression (GWR) to account for geographical variations in the parameters of destination attractiveness and travel cost in the agent-based model. We conducted a case study in Ningbo, China, using trip diaries, census data, and over 1.5 million taxi trip records. Our agent-based model showed superior performance in predicting citizens’ movements and activities after a new shopping area in Ningbo was built, compared with a model without local calibration. The results also revealed the geographic sensitivity to destinations and the effects of a passenger's motivations that underpin human movement.},
   author = {Shuhui Gong and Xiangrui Dong and Kaiqi Wang and Bingli Lei and Zizhao Jia and Jiaxin Qin and Chris Roadknight and Yu Liu and Rui Cao},
   doi = {10.1016/j.jag.2023.103368},
   issn = {1872826X},
   journal = {International Journal of Applied Earth Observation and Geoinformation},
   keywords = {Activity-based analysis,Agent-based modelling (ABM),Geographically weighted regression (GWR),Huff model,Taxi GPS trajectories},
   month = {8},
   publisher = {Elsevier B.V.},
   title = {Agent-based modelling with geographically weighted calibration for intra-urban activities simulation using taxi GPS trajectories},
   volume = {122},
   year = {2023},
}
@inproceedings{Zilske2014,
   abstract = {We investigate replacing travel diaries with sets of call detail records (CDRs) as input data for an agent-oriented traffic simulation. Synthetic CDRs are used in order to study the effect of this substitution in isolation. We introduce an experimental design where a detailed synthetic transportation scenario with individual simulated travellers is combined with a simple model of mobile phone usage to collect synthetic CDRs. This set of artificial CDRs is then considered as input for another instance of the same traffic model, disregarding all other information. We analyse to what degree the model reproduces the base case, depending on the frequency of the available CDRs. © 2014 Published by Elsevier B.V.},
   author = {Michael Zilske and Kai Nagel},
   doi = {10.1016/j.procs.2014.05.494},
   issn = {18770509},
   journal = {Procedia Computer Science},
   keywords = {Mobile phone data,Multi-agent simulation,Transport simulation},
   pages = {802-807},
   publisher = {Elsevier B.V.},
   title = {Studying the accuracy of demand generation from mobile phone trajectories with synthetic data},
   volume = {32},
   year = {2014},
}
@misc{Day2008,
   author = {Nicholas Day},
   title = {The Joint Modelling of Trip Timing and Mode Choice},
   year = {2008},
}
@misc{,
   author = {Xiyuan Ren and Joseph Y J Chow},
   keywords = {Activity-based modeling,Inverse Optimization,Shanghai,big data,utility maximization},
   title = {A random-utility-consistent machine learning method to estimate agents' joint activity scheduling behavior from ubiquitous data},
}
@article{Enam2017,
   abstract = {The primary objective of this study was to contribute to the literature on activity pattern generation. In this paper, a new framework is proposed for simultaneously modeling the following tour and stop-making decisions: the number and purpose of tours conducted in a day, time allocated to different tours, number and purpose of stops conducted within each tour, and time allocated to different stops. The framework represents time as a continuous entity and explicitly considers the time constraints within which an individual operates when generating tours and stops. In addition, the framework is capable of accounting for the interrelationships across different tour- and stop-level decisions. The model formulation that operationalizes the proposed framework imitates a bi-level structure in which the participation (whether to pursue) and time allocation (how much time) decisions for daily tours are modeled at the upper level. Within each tour, participation and time allocation decisions for different stops are modeled at the lower level. The model formulation for the bi-level structure builds on the utility theoretic multiple discrete continuous probit modeling approach. The proposed framework and model formulation are demonstrated with an empirical case study using data from the 2008–2009 National Household Travel Survey. Replication and forecasting results are presented to demonstrate the feasibility and applicability of the proposed framework and model formulation. The results provide evidence in support of the bi-level structure and its ability to capture the various constraints and interrelationships across tour- and stop-level participation and time allocation decisions.},
   author = {Annesha Enam and Karthik C. Konduri},
   doi = {10.3141/2665-08},
   issn = {21694052},
   issue = {1},
   journal = {Transportation Research Record},
   pages = {69-79},
   publisher = {SAGE Publications Ltd},
   title = {Day Pattern Generation System for Jointly Modeling Tours and Stops: Bi-Level Multiple Discrete Continuous Probit Model},
   volume = {2665},
   year = {2017},
}
@article{Ho2013,
   abstract = {Joint household travel, with or without joint participation in an activity, constitutes a fundamental aspect in modelling activity-based travel behaviour. This paper examines joint household travel arrangements and mode choices using a utility maximising approach. An individual tour-based mode choice model is formulated contingent on the choice of joint tour patterns where joint household activities and shared ride arrangements are recognised as part of the joint household decision-making that influences the travel modes of each household member. Two models, one for weekend and one for weekday, are estimated using empirical data from the Sydney Household Travel Survey. The results show that weekend travel is characterised by a high joint household activity participation rate while weekday travel is distinguished by more intra-household shared ride arrangements. The arrangements of joint household travel are highly associated with travel purpose, social and mobility constraints and household resources. On weekends, public transport is mainly used by captive users (i.e., no-car households and students) and its share is about half of that on weekdays. Also, the value of travel time savings (VOTs) are found to be higher on weekends than on weekdays, running entirely counter to the common belief that weekend VOTs are lower than weekday VOTs. This paper highlights the importance of studying joint household travel and using different transport management measures for alleviating traffic congestion on weekdays and weekends. © 2013 Springer Science+Business Media New York.},
   author = {Chinh Ho and Corinne Mulley},
   doi = {10.1007/s11116-013-9479-0},
   issn = {00494488},
   issue = {4},
   journal = {Transportation},
   keywords = {Activity-based modelling,Intra-household interactions,Joint travel,Mode choice,VOT,Weekend travel},
   month = {7},
   pages = {789-811},
   title = {Tour-based mode choice of joint household travel patterns on weekend and weekday},
   volume = {40},
   year = {2013},
}
@article{Yasmin2017,
   abstract = {Validation is an essential part of the model development process for practical applications in the real-world context. This paper focuses on how and at which level the validation of activity-based travel demand models must be performed. It then examines the spatial transferability, as a validation test, of an activity-based model, TASHA (Travel Activity Scheduler for Household Agents). This paper applies the TASHA model to the Island of Montreal, Canada, using the 2003 Origin–Destination (O–D) travel survey and the 2001 Canadian Census, and validates the transfer by comparing modelled and observed activity attributes at three different levels of aggregation. Validation results at different levels (especially at macro-, and meso-level) seem quite promising. TASHA can successfully reproduce activity behaviours of another context, at least for fixed activities (work, school) with a few exceptions.},
   author = {Farhana Yasmin and Catherine Morency and Matthew J. Roorda},
   doi = {10.1080/23249935.2016.1249437},
   issn = {23249943},
   issue = {3},
   journal = {Transportmetrica A: Transport Science},
   keywords = {Montreal,TASHA,Travel demand modelling,activity-based model,model validation,spatial transferability},
   month = {3},
   pages = {222-249},
   publisher = {Taylor and Francis Ltd.},
   title = {Macro-, meso-, and micro-level validation of an activity-based travel demand model},
   volume = {13},
   year = {2017},
}
@article{Koushik2020,
   abstract = {This paper reviews the activity-travel behaviour literature that employs Machine Learning (ML) techniques for empirical analysis and modelling. Machine Learning algorithms, which attempt to build intelligence utilizing the availability of large amounts of data, have emerged as powerful tools in the fields of pattern recognition and big data analysis. These techniques have been applied in activity-travel behaviour studies since the early ’90s when Artificial Neural Networks (ANN) were employed to model mode choice decisions. AMOS, an activity-based modelling system developed in the mid-’90s, has ANN at its core to model and predict individual responses to travel demand management measures. In the dawn of 2000, ALBATROSS, a comprehensive activity-based travel demand modelling system, was proposed by Arentze and Timmermans using Decision Trees. Since then researchers have been exploring ML techniques like Support Vector Machines (SVM), Decision Trees (DT), Neural Networks (NN), Bayes Classifiers, and more recently, Ensemble Learners to model and predict activity-travel behaviour. A large number of publications over the years and an upward trend in the number of published articles over time indicate that Machine Learning is a promising tool for activity-travel behaviour analysis and prediction. This article, first of its kind in the literature, reviews these studies and explores the trends in activity-travel behaviour research that apply ML techniques. The review finds that mode choice decisions have received wide attention in the literature on ML applications. It was observed that most of the studies identify the lack of interpretability as a serious shortcoming in ML techniques. However, very few studies have attempted to improve the interpretability of the models. Further, some studies report the importance of feature engineering in ML-based studies, but very few studies adopt feature engineering before model development. Spatiotemporal transferability of models is another issue that has received minimal attention in the literature. In the end, the paper discusses possible directions for future research in the area of activity-travel behaviour modelling using ML techniques.},
   author = {Anil N.P. Koushik and M. Manoj and N. Nezamuddin},
   doi = {10.1080/01441647.2019.1704307},
   issn = {14645327},
   issue = {3},
   journal = {Transport Reviews},
   keywords = {Activity-based models,Decision Trees,Neural Networks,Support Vector Machines,Travel demand modelling},
   month = {5},
   pages = {288-311},
   publisher = {Routledge},
   title = {Machine learning applications in activity-travel behaviour research: a review},
   volume = {40},
   year = {2020},
}
@article{,
   abstract = {Understanding the travel behavior of individuals grouped by similar time-use activity patterns can contribute greatly to modeling regional spatial and temporal patterns of transport demand. In this paper, we present a comprehensive modeling framework to forecast and replicate individuals’ travel behavior, labeled as the Scheduler for Activities, Locations, and Travel (SALT). The prototype version of the SALT framework comprises a series of modules that employ behaviorally-based econometric, machine-learning, and data-mining techniques. The SALT model is cross-validated with 30% of the out-of-home sample survey data from the large Halifax Space Time Activity Research (STAR) household survey. Results show that the SALT scheduling model is able to assemble the travelers’ 24-hour schedules with an average 82% accuracy compared to the observed data. The proposed simulation modeling framework is useful for deeper understanding of individuals’ activity-travel decisions and may be utilized to examine sensitive policy issues such as transportation control measures and congestion-pricing.},
   author = {Mohammad Hesam Hafezi and Naznin Sultana Daisy and Hugh Millward and Lei Liu},
   doi = {10.1080/23249935.2021.1921879},
   issn = {23249943},
   issue = {2},
   journal = {Transportmetrica A: Transport Science},
   keywords = {Activity-travel,daily activity,machine-learning,travel behavior,travel demand},
   pages = {248-280},
   publisher = {Taylor and Francis Ltd.},
   title = {Framework for development of the Scheduler for Activities, Locations, and Travel (SALT) model},
   volume = {18},
   year = {2022},
}
@article{Khaddar2023,
   abstract = {This paper presents an episode-level activity generation and destination choice model. The model accommodates the occurrence of multiple episodes of an activity and captures interdependencies among travel choice dimensions that vary at the episode-level such as occurrence, duration, and destinations of episodes. A multiple discrete-continuous extreme value model with ordered preferences (MDCEV-OP) is adopted. This ordered preference extension of the modified MDCEV model imposes a restriction that the higher-numbered episodes do not occur without the occurrence of lower-numbered episodes. Further, destination accessibility from the destination choice utility is derived using a multinomial logit (MNL) model, which provides feedback to the MDCEV-OP through a logsum component. The findings of this study demonstrate the benefits of modeling activity engagement, duration, and destination at the granular level of episodes, including offering an enhanced behavioral realism of the model and the potential to improve forecasting accuracy and insights of activity-based models.},
   author = {Shivam Khaddar and Shobhit Saxena and Mahmudur Rahman Fatmi and Abdul Rawoof Pinjari},
   doi = {10.1080/19427867.2022.2102347},
   issn = {19427875},
   issue = {8},
   journal = {Transportation Letters},
   keywords = {Multiple discrete-continuous choice models,activity duration,activity engagement,destination accessibility,episode-level activity generation},
   pages = {860-870},
   publisher = {Taylor and Francis Ltd.},
   title = {An Episode-Level Joint Model for Activity Engagement, Duration, and Destination Location Choice Decisions},
   volume = {15},
   year = {2023},
}
@article{Khan2022,
   abstract = {This paper presents the validation analysis of an activity-based travel demand modeling system–shorter-term decisions simulator (SDS). It compares microsimulation results of SDS with observed census and travel-activity survey data for the base year 2006, and forecasting years–2016 and 2018. Base year validation suggests SDS’s reasonable capability to replicate observed data as indicated by lower absolute percentage error (APE) measures. SDS exhibits satisfactory performance for the forecasting years as well. For instance, Kolmogorov–Smirnov (KS) tests during the activity start time and duration analysis for year 2018 yield smaller D-values than critical values, which indicates a better fit model. Prediction of tour-level mode choice, shared travel choice, and vehicle allocation also exhibit good accuracy (± 4%). Validation results presented in this study demonstrate SDS’s promising forecasting capability so that the model can be utilized efficiently to develop and test alternative land use and travel demand management strategies.},
   author = {Nazmul Arefin Khan and Hasan Shahrier and Muhammad Ahsanul Habib},
   doi = {10.1080/19427867.2021.1988437},
   issn = {19427875},
   issue = {9},
   journal = {Transportation Letters},
   keywords = {Activity-based modeling,microsimulation,shorter-term decisions simulator (SDS),travel demand forecasting,validation},
   pages = {1004-1018},
   publisher = {Taylor and Francis Ltd.},
   title = {Validation of an activity-based travel demand modeling system},
   volume = {14},
   year = {2022},
}
@article{Khan2022,
   abstract = {This paper presents the estimation and microsimulation results of tour-level shared travel choice, activity participation and time allocation decisions. It estimates shared travel choices for mandatory, maintenance and discretionary activity-tours by developing mixed logit models. To understand behavioral complexities of different activity attributes, this study develops a multiple discrete–continuous extreme value model that estimates the joint decision of activity-based tour participation and time allocation. It accommodates the influence of individuals’ social utility within the modeling framework, which is represented by logsum values derived from shared travel decisions. Furthermore, this study presents the microsimulation of individuals’ shared travel choice, activity participation and time allocation decisions over a simulated period within an activity-travel modeling system–shorter-term decisions simulator (SDS). SDS modeling framework implements a feedback from shared travel choice to activity participation decisions via logsum values, so that the activity-travel decisions are simulated in a more behaviourally plausible way.},
   author = {Nazmul Arefin Khan and Muhammad Ahsanul Habib},
   doi = {10.1080/23249935.2021.1876178},
   issn = {23249943},
   issue = {3},
   journal = {Transportmetrica A: Transport Science},
   keywords = {Shared travel choice,activity participation,microsimulation,multiple discrete–continuous extreme value model,social utility,time allocation},
   pages = {494-531},
   publisher = {Taylor and Francis Ltd.},
   title = {Modeling activity-based tour shared travel choices, tour-level activity participation and time allocation},
   volume = {18},
   year = {2022},
}
@article{Khan2023,
   abstract = {This paper presents the findings of an activity-based tour-level model that jointly investigates individuals’ decisions of activity-tour participation, time allocation, and mode choice. A multiple discrete continuous extreme value (MDCEV) model is developed that explores the participation and time allocation decisions for mandatory, maintenance, and discretionary activity-tour types. Mixed logit (MXL) models are developed to evaluate the mode choice decisions of individuals for different activity-based tours. Logsum values, which represent the modal accessibility, are introduced within the MDCEV modeling framework as feedback mechanisms from mixed logit models that exclusively examine the influence of individuals’ mode choice on their activity-tour engagement decisions as well as ensure the integrity of the decision modeling system. Findings of this study would assist the policymakers to develop effective strategies for better transportation investment decisions.},
   author = {Nazmul Arefin Khan and Annesha Enam and Muhammad Ahsanul Habib and Karthik C. Konduri},
   doi = {10.1080/19427867.2022.2144381},
   issn = {19427875},
   issue = {9},
   journal = {Transportation Letters},
   keywords = {Activity-based tour mode choice,Tour-level activity participation and time allocation,mixed logit model,modal accessibility,multiple discrete continuous extreme value model},
   pages = {1191-1201},
   publisher = {Taylor and Francis Ltd.},
   title = {Exploring joint activity-tour participation, time allocation, and mode choice decisions},
   volume = {15},
   year = {2023},
}
@article{Lyu2022,
   abstract = {Multi-state supernetworks are capable of representing activity-travel patterns at a high level of detail and thus are a powerful tool for activity-travel scheduling (ATS) of multidimensional choice facets. To alleviate the limitations of the common deterministic network representation, travel time and activity duration uncertainty has been incorporated in multi-state supernetworks. However, the extension unrealistically assumed that all uncertain components are independent. This study suggests an approach of ATS considering spatially and temporally correlated travel times and activity durations in stochastic time-dependent (STD) multi-state supernetworks. Support points are used as a representation of the stochasticity of the STD multi-state supernetwork. ATS is formulated as a pathfinding problem subject to space–time constraints based on recursive formulations. A series of numerical experiments is implemented to demonstrate the applicability of the suggested approach.},
   author = {Jing Lyu and Feixiong Liao and Soora Rasouli and Harry Timmermans},
   doi = {10.1080/23249935.2021.1937374},
   issn = {23249943},
   issue = {3},
   journal = {Transportmetrica A: Transport Science},
   keywords = {Activity-travel scheduling,multi-state supernetwork,support point,temporal and spatial dependencies,uncertainty},
   pages = {1300-1324},
   publisher = {Taylor and Francis Ltd.},
   title = {Activity-travel scheduling in stochastic multi-state supernetworks with spatial and temporal correlations},
   volume = {18},
   year = {2022},
}
@article{Zhuge2019,
   abstract = {This paper attempts to apply both global and local sensitivity analyses (SA) to fully test the integrated activity-based model (ABM) within several experiments based on a Chinese medium-sized city, Baoding. MATSim (Multi-agent Transport Simulation) that is a typical integrated ABM is used as an example for the SA. The global SA, which is based on the elementary effect method, is firstly applied to identify the influential parameters. Then the once-at-a-time (OAT)-based Local SA is employed to further reveal the relationship between the influential parameters and the outputs of interest, such as traffic flow. The SA results show the extent to which and how three influential MATSim parameters (population scaling factor, the number of iterations and time step size) influence the outputs of interest. In addition, the SA results of MATSim suggest that the parameters of time mutation rate and performing utility can heavily influence the outputs of interest and properly setting them can optimize the daily plans of agents. Finally, this paper concludes with suggestions on how to wisely use the SA findings for both MATSim and other ABM users.},
   author = {Chengxiang Zhuge and Chunfu Shao and Shuling Wang and Ying Hu},
   doi = {10.1080/19427867.2017.1286772},
   issn = {19427875},
   issue = {2},
   journal = {Transportation Letters},
   keywords = {Integrated activity-based model,MATSim,dynamic traffic assignment,elementary effect method,global sensitivity analysis,local sensitivity analysis,once-at-a-time method,parameter sensitivity analysis},
   month = {3},
   pages = {93-103},
   publisher = {Taylor and Francis Ltd.},
   title = {Sensitivity analysis of integrated activity-based model: using MATSim as an example},
   volume = {11},
   year = {2019},
}
@article{Borysov2019,
   abstract = {Population synthesis is concerned with the generation of synthetic yet realistic representations of populations. It is a fundamental problem in the modeling of transportation where the synthetic populations of micro-agents represent a key input to most agent-based models. In this paper, a new methodological framework for how to ‘grow’ pools of micro-agents is presented. The model framework adopts a deep generative modeling approach from machine learning based on a Variational Autoencoder (VAE). Compared to the previous population synthesis approaches, including Iterative Proportional Fitting (IPF), Gibbs sampling and traditional generative models such as Bayesian Networks or Hidden Markov Models, the proposed method allows fitting the full joint distribution for high dimensions. The proposed methodology is compared with a conventional Gibbs sampler and a Bayesian Network by using a large-scale Danish trip diary. It is shown that, while these two methods outperform the VAE in the low-dimensional case, they both suffer from scalability issues when the number of modeled attributes increases. It is also shown that the Gibbs sampler essentially replicates the agents from the original sample when the required conditional distributions are estimated as frequency tables. In contrast, the VAE allows addressing the problem of sampling zeros by generating agents that are virtually different from those in the original data but have similar statistical properties. The presented approach can support agent-based modeling at all levels by enabling richer synthetic populations with smaller zones and more detailed individual characteristics.},
   author = {Stanislav S. Borysov and J. Rich and Francisco C. Pereira},
   doi = {10.1016/j.trc.2019.07.006},
   issn = {0968090X},
   journal = {Transportation Research Part C: Emerging Technologies},
   keywords = {Agent-based modeling,Deep learning,Generative modeling,Population synthesis,Transportation modeling,Variational Autoencoder},
   month = {9},
   pages = {73-97},
   publisher = {Elsevier Ltd},
   title = {How to generate micro-agents? A deep generative modeling approach to population synthesis},
   volume = {106},
   year = {2019},
}
@misc{,
   abstract = {本論文では，東京都市圏を対象として開発された移動・活動パターンシミュレータ "東京都市圏ACT (T-ACT)"について，開発に至った経緯，T-ACTモデル構造上の特 徴，シミュレータの現況再現性の検証，多様な都市交通政策の定量分析への適用可能 性について詳説する．T-ACTは，(1) 個人データ生成モデル，(2) アクティビティベー スドモデル (ABM)，(3) 交通量配分モデルから構成されている．特に，ABMにおいて 簡便ながらも現況再現性の高い離散選択型の階層モデル構造を採用していることや， 交通量配分において東京都市圏の交通の特徴の一つである鉄道利用シェアの大きさ に鑑みた細密な鉄道経路配分モデルを導入している点に特徴がある．構築したモデル システムのシミューレーション結果については，幾つかの大規模交通調査による実測 値との比較から，詳細な属性別に見ても十分な現況再現性が得られていることが確認 された．また，近い将来に起こりうる新たな都市活動や新モビリティの普及を想定し た都市圏レベルでの将来シミュレーションのケーススタディを通じて，社会情勢の変 化や施策が個人の活動に与える影響を適切に分析できることも確認された．},
   author = {石井 良治 and 福田 大輔 and 柳沼 秀樹 and 日下部 貴彦 and 茂木 渉 and 磯野 昂士 and 渋川 剛史 and 末成 浩嗣 and 西 隆太 and 伊藤 祥太 Ryoji Ishii and Daisuke Fukuda and Hideki Yaginuma and Takahiko Kusakabe and Wataru Mogi and Koshi Isono and Takeshi Shibukawa and Koji Suenari and Ryuta Nishi and Shota Ito},
   keywords = {Applied Activity-Based Model System,Microsimulation,Quasi-Dynamic Assignment},
   title = {移動・活動パターンシミュレータ"東京都市圏 ACT"の開発と 都市交通政策検討への活用 Development of "Tokyo Metropolitan Area Activity-Travel Patterns Simulator" (T-ACT) and its Application to the Evaluation of Urban Transportation Policy},
}
@article{Rasouli2014,
   abstract = {Because two decades have almost passed since the introduction of activity-based models of travel demand, this seems the right time to evaluate progress made in the development and application of these models. This invited paper seeks to discuss the initial promises of activity-based models as an alternative to four-step and tour-based models, summarize progress made and identify still unsolved issues that require further research. © 2013 © 2013 The Institute of Urban Sciences.},
   author = {Soora Rasouli and Harry Timmermans},
   doi = {10.1080/12265934.2013.835118},
   issn = {12265934},
   issue = {1},
   journal = {International Journal of Urban Sciences},
   keywords = {activity-based models,transport,travel demand forecasting},
   month = {1},
   pages = {31-60},
   title = {Activity-based models of travel demand: Promises, progress and prospects},
   volume = {18},
   year = {2014},
}
@misc{,
   author = {Ryuichi Kitamura and Satoshi Fujii},
   title = {TWO COMPUTATIONAL PROCESS MODELS OF ACTIVITY-TRAVEL BEHAVIOR 1},
}
@article{Arentze2004,
   abstract = {This paper describes the conceptual development, operatonalization and empirical testing of Albatross: A Learning-based Transportation Oriented Simulation System. This activity-based model of activity-travel behavior is derived from theories of choice heuristics that consumers apply when making decisions in complex environments. The model, one of the most comprehensive of its kind, predicts which activities are conducted when, where, for how long, with whom, and the transport mode involved. In addition, various situational, temporal, spatial, spatial-temporal and institutional constraints are incorporated in the model. The decision tree is proposed as a formalism to represent an exhaustive set of mutually exclusive rules for each decision step in the model. A CHAID decision tree induction method is used to derive decision trees from activity diary data. The case study conducted to develop and test the model indicates that performance of the model is very satisfactory. We conclude therefore that the methodology proposed in this article is useful to develop computational process models of activity-travel choice behavior. © 2003 Elsevier Ltd. All rights reserved.},
   author = {Theo A. Arentze and Harry J.P. Timmermans},
   doi = {10.1016/j.trb.2002.10.001},
   issn = {01912615},
   issue = {7},
   journal = {Transportation Research Part B: Methodological},
   keywords = {Activity-based modeling,Computational process modeling,Decision tree induction,Reinforcement learning},
   pages = {613-633},
   publisher = {Elsevier Ltd},
   title = {A learning-based transportation oriented simulation system},
   volume = {38},
   year = {2004},
}
@misc{,
   abstract = {This paper describes the conceptual development, operationalization and empirical testing of Albatross: A Learning Based Transportation Oriented Simulation System. This activity-based model of activity-travel behavior is derived from theories of choice heuristics that consumers apply when making decisions in complex environments. The model, one of the most comprehensive of its kind, predicts which activities are conducted when, where, for how long, with whom, and the transport mode involved. In addition, various situational, temporal, spatial, spatial-temporal and institutional constraints are incorporated in the model. The decision tree is proposed as a formalism to represent an exhaustive set of mutual exclusive rules for each decision step in the model. A CHAID decision tree induction method is used to derive decision trees from activity diary data. The case study conducted to develop and test the model indicates that performance of the model is very satisfactory. We conclude therefore that the methodology proposed in this article is useful to develop computational process models of activity-travel choice behavior.},
   author = {Theo A Arentze and Harry J P Timmermans},
   keywords = {activity-based modeling,computational process modeling,decision tree induction,reinforcement learning},
   title = {ALBATROSS-A LEARNING-BASED TRANSPORTATION ORIENTED SIMULATION SYSTEM},
}
@article{,
   abstract = {This paper presents a utility-maximizing approach to agent-based modeling with an application to the Greater Boston Area (GBA). It leverages day activity schedules (DAS) to create a framework for representing travel demand in an individual’s day. DAS are composed of a sequence of stops that make up home-based tours with activity purposes, intermediate stops, and subtours. The framework introduced in this paper includes three levels: (1) the Day Pattern Level, which determines if an individual will travel and, if so, what types of primary activities and intermediate stops they will do; (2) the Tour Level, which models the mode, destination, and time-of-day of the different primary activities; and (3) the Intermediate Stop Level, which generates intermediate stops. The models are estimated for the GBA using the 2010 Massachusetts Travel Survey (MTS). They are then implemented in SimMobility, the agent-based, activity-based, multimodal simulator. It run in a microsimulation using a Synthetic Population. Produced results are consistent with the MTS. Compared with similar activity-based approaches, the proposed framework allows for more flexibility in modeling a wide range of activity and travel patterns.},
   author = {Isabel Viegas de Lima and Mazen Danaf and Arun Akkinepally and Carlos Lima De Azevedo and Moshe Ben-Akiva},
   doi = {10.1177/0361198118798970},
   issn = {21694052},
   issue = {49},
   journal = {Transportation Research Record},
   month = {12},
   pages = {146-157},
   publisher = {SAGE Publications Ltd},
   title = {Modeling Framework and Implementation of Activity- and Agent-Based Simulation: An Application to the Greater Boston Area},
   volume = {2672},
   year = {2018},
}
@misc{,
   abstract = {Over 30 years have passed since activity-based travel demand models (ABMs) emerged to overcome the limitations of the preceding models which have dominated the field for over 50 years. Activity-based models are valuable tools for transportation planning and analysis, detailing the tour and mode-restricted nature of the household and individual travel choices. Nevertheless, no single approach has emerged as a dominant method, and research continues to improve ABM features to make them more accurate, robust, and practical. This paper describes the state of art and practice, including the ongoing ABM research covering both demand and supply considerations. Despite the substantial developments, ABM's abilities in reflecting behavioral realism are still limited. Possible solutions to address this issue include increasing the inaccuracy of the primary data, improved integrity of ABMs across days of the week, and tackling the uncertainty via integrating demand and supply. Opportunities exist to test, the feasibility of spatial transferability of ABMs to new geographical contexts along with expanding the applicability of ABMs in transportation policy-making.},
   author = {Atousa Tajaddini and Geoffrey Rose and Kara M Kockelman and Hai L Vu},
   keywords = {activity-based models,big data,transferability of transport demand models,transportation planning,travel demand forecasting},
   title = {Chapter Recent Progress in Activity-Based Travel Demand Modeling: Rising Data and Applicability},
   url = {www.intechopen.com},
}
@misc{Balmer2008,
   author = {M Balmer and K Meister and M Rieser and K Nagel and K W Axhausen},
   title = {Agent-based simulation of travel demand: Structure and computational performance of MATSim-T},
   year = {2008},
}
@misc{,
   abstract = {and so on. Since not all this activity can be done at the same location , they have to travel, thus producing traffic. To plan an efficient day, each person makes many decisions: • Which route should I take to get to work? (route choice decision) • Which mode should I use to go to the lake? (mode choice decision) • Should I drink another beer before going home? (activity duration choice decision) • Should I go shopping near my home or at the mall? (location choice decision) • When should I play tennis today? (activity starting time choice decision) • Should I go to visit a friend? (activity type choice decision) • Who should I take along? (group composition decision) • Should I go swimming before or after work? (activity sequence decision) There are more decisions to make; some of them are made hours (days, months) in advance, whereas others are made spontaneously as a reaction to specific circumstances. Many decisions induce other decisions. For example, if one is late for work, one must work longer, leaving no time to go shopping that day; therefore, one will need time tomorrow to do the shopping. This example shows the importance of describing schedules for each individual in a simulation model because it is the schedule and the decisions made by the person who adheres to this schedule that produce traffic. To simulate a typical day in an urban area, microsimulation tools require information about the schedule of each individual and some knowledge about people's decision-making processes. The challenge is to create this individual demand out of general input data. In practice, there is a large variety of input data. These data can differ in quality, spatial resolution, purpose, and so on. The challenge for a flexible demand-modeling framework is to combine this variety to produce individual schedules. In addition, the data have to define precise interfaces to provide portability to other models and programs, and they should be suitable for large-scale scenarios that include many millions of individuals. Since the model should be adaptable to the given input data, the framework needs to be easily extensible with new packages, algorithms, and models. Such a modeling framework is presented for large-scale scenarios. After a summary about related research and a description of the program structure, the framework is used to model daily demand for two different scenarios. One is a medium-resolution scenario that takes place in the canton of Zurich and consists of about 1.3 million individuals. The second large-scale scenario is defined for Berlin and Brandenburg for about 7 million inhabitants. The two scenarios differ in the amount of available information, spatial resolution, and size, as well as in the demand-modeling process itself. Microsimulation is becoming increasingly important in traffic demand modeling. The major advantage over traditional four-step models is the ability to simulate each traveler individually. Decision-making processes can be included for each individual. Traffic demand is the result of the different decisions made by individuals; these decisions lead to plans that the individuals then try to optimize. Therefore, such microsimulation models need appropriate initial demand patterns for all given individuals. The challenge is to create individual demand patterns out of general input data. In practice, there is a large variety of input data, which can differ in quality, spatial resolution, purpose, and other characteristics. The challenge for a flexible demand-modeling framework is to combine the various data types to produce individual demand patterns. In addition , the modeling framework has to define precise interfaces to provide portability to other models, programs, and frameworks, and it should be suitable for large-scale applications that use many millions of individuals. Because the model has to be adaptable to the given input data, the framework needs to be easily extensible with new algorithms and models. The presented demand-modeling framework for large-scale scenarios fulfils all these requirements. By modeling the demand for two different scenarios (Zurich, Switzerland, and the German states of Berlin and Brandenburg), the framework shows its flexibility in aspects of diverse input data, interfaces to third-party products, spatial resolution, and last but not least, the modeling process itself.},
   author = {M Balmer and K W Axhausen},
   keywords = {Category IA},
   title = {TRR 1985},
   url = {http://tmip.fhwa.dot.gov/transims},
}
@article{Arentze2004,
   abstract = {This paper describes the conceptual development, operatonalization and empirical testing of Albatross: A Learning-based Transportation Oriented Simulation System. This activity-based model of activity-travel behavior is derived from theories of choice heuristics that consumers apply when making decisions in complex environments. The model, one of the most comprehensive of its kind, predicts which activities are conducted when, where, for how long, with whom, and the transport mode involved. In addition, various situational, temporal, spatial, spatial-temporal and institutional constraints are incorporated in the model. The decision tree is proposed as a formalism to represent an exhaustive set of mutually exclusive rules for each decision step in the model. A CHAID decision tree induction method is used to derive decision trees from activity diary data. The case study conducted to develop and test the model indicates that performance of the model is very satisfactory. We conclude therefore that the methodology proposed in this article is useful to develop computational process models of activity-travel choice behavior. © 2003 Elsevier Ltd. All rights reserved.},
   author = {Theo A. Arentze and Harry J.P. Timmermans},
   doi = {10.1016/j.trb.2002.10.001},
   issn = {01912615},
   issue = {7},
   journal = {Transportation Research Part B: Methodological},
   keywords = {Activity-based modeling,Computational process modeling,Decision tree induction,Reinforcement learning},
   pages = {613-633},
   publisher = {Elsevier Ltd},
   title = {A learning-based transportation oriented simulation system},
   volume = {38},
   year = {2004},
}
@article{,
   title = {Incorporating_Feedback_in_Travel_Forecas},
}
@misc{,
   author = {Davide Boyce and Yu-Fang Zhang and Mary R Lupa},
   title = {Transportation Research Record No. 1443, Travel Demand Modeling and Network Assignment Models},
}
@book{,
   abstract = {Resource simultaneously available in PDF, EPUB format, and MOBI format. "The MATSim (Multi-Agent Transport Simulation) software project was started around 2006 with the goal of generating traffic and congestion patterns by following individual synthetic travelers through their daily or weekly activity programme. It has since then evolved from a collection of stand-alone C++ programs to an integrated Java-based framework which is publicly hosted, open-source available, automatically regression tested. It is currently used by about 40 groups throughout the world. This book takes stock of the current status. The first part of the book gives an introduction to the most important concepts, with the intention of enabling a potential user to set up and run basic simulations. The second part of the book describes how the basic functionality can be extended, for example by adding schedule-based public transit, electric or autonomous cars, paratransit, or within-day replanning. For each extension, the text provides pointers to the additional documentation and to the code base. It is also discussed how people with appropriate Java programming skills can write their own extensions, and plug them into the MATSim core. The project has started from the basic idea that traffic is a consequence of human behavior, and thus humans and their behavior should be the starting point of all modelling, and with the intuition that when simulations with 100 million particles are possible in computational physics, then behavior-oriented simulations with 10 million travelers should be possible in travel behavior research. The initial implementations thus combined concepts from computational physics and complex adaptive systems with concepts from travel behavior research. The third part of the book looks at theoretical concepts that are able to describe important aspects of the simulation system; for example, under certain conditions the code becomes a Monte Carlo engine sampling from a discrete choice model. Another important aspect is the interpretation of the MATSim score as utility in the microeconomic sense, opening up a connection to benefit cost analysis. Finally, the book collects use cases as they have been undertaken with MATSim. All current users of MATSim were invited to submit their work, and many followed with sometimes crisp and short and sometimes longer contributions, always with pointers to additional references. We hope that the book will become an invitation to explore, to build and to extend agent-based modeling of travel behavior from the stable and well tested core of MATSim documented here." Part I: Using MATSim -- Part II: Extending MATSim -- Subpart One: Input Data Preparation -- Subpart Two: Mobsim -- Subpart Three: Individual Car Traffic -- Subpart Four: Other Modes Besides Individual Car -- Subpart Five: Commercial Traffic -- Subpart Six: Additional Choice Dimensions -- Subpart Seven: Within-Day Replanning -- Subpart Eight: Automatic Calibration -- Subpart Nine: Visualizers -- Subpart Ten: Analysis -- Subpart Eleven: Computational Performance Improvements -- Subpart Twelve: Other Modules -- Subpart Thirteen: Development Process & Own Modules -- Part III: Understanding MATSim -- Part IV: Scenarios.},
   author = {Andreas Horni and Kai Nagel and K. W. Axhausen},
   isbn = {9781909188754},
   pages = {586},
   title = {The multi-agent transport simulation MATSim},
}
@article{Maheshwari2023,
   abstract = {New transport technologies have historically influenced how cities are shaped, while urban form is known to influence travel behaviour. But this reciprocal relationship is seldom operationalized in practice due to the disciplinary gap between urban design and transport planning. The two are often linked through a ‘predict and provide’ workflow, which is problematic in the context of emerging technologies such as AVs. This paper argues for a more iterative design and transport simulation workflow, through design experiments. One design experiment is illustrated using Sketch MATSim, to investigate the impact of network design on the performance of shared automated vehicles.},
   author = {Tanvi Maheshwari and Pieter Fourie and Sergio Arturo Ordoñez Medina and Kay W. Axhausen},
   doi = {10.1080/13574809.2023.2214080},
   issn = {14699664},
   journal = {Journal of Urban Design},
   keywords = {MATSim,Transport simulation,autonomous vehicles,planning support tools,shared mobility},
   publisher = {Routledge},
   title = {Iterative urban design and transport simulation using Sketch MATSim},
   year = {2023},
}
@article{,
   abstract = {Permanent link: https://doi.},
   doi = {10.3929/ethz-a-005946820},
   title = {ETH Library Implementations of within day replanning in MATSim-T},
   url = {https://doi.org/10.3929/ethz-a-005946820},
}
@article{Bifulco2010,
   abstract = {Purpose In this paper an activity-based modelling framework is presented. It enhances many of the characteristics of existing approaches and enables a more accurate travel demand modelling. Methods: The model approach proposed explicitly takes into account the households' role, as well as time and space constraints. Issues related to activity participation and activity planning are explicitly addressed with respect to the horizon of a whole week. The proposed framework allows to reproduce activity lists and activity patterns in an explicit and consistent way. As a consequence, time and mode characteristics of travel demand are more accurately computed. The approach has been designed in order to capture interactions among households members and to explicitly represent trip-chains and relationships between trips within activity patterns. In this paper a comprehensive formalisation of the modelling framework is presented and part of it is estimated on the basis of ad-hoc collected data. Application: The modelling framework has been then applied to the Naples' metropolitan area (southern Italy), a catchment area with about three million inhabitants. Results and Conclusions: The proposed framework has shown a satisfying flexibility, as well as a good ability in reproducing real data. It seems to be a good compromise between accuracy and operative issues, which improves the range of reproducible mobility phenomena and the accuracy of this reproduction and at the same time it moves some step forward the practical applicability of activity-based approaches. © 2010 The Author(s).},
   author = {Gennaro Nicola Bifulco and Armando Cartenì and Andrea Papola},
   doi = {10.1007/s12544-010-0040-3},
   issn = {18670717},
   issue = {4},
   journal = {European Transport Research Review},
   keywords = {Activity-based,Demand model,Nested logit,RP survey,Transport model,Travel behaviours},
   month = {12},
   pages = {209-221},
   title = {An activity-based approach for complex travel behaviour modelling},
   volume = {2},
   year = {2010},
}
@article{Jensen1990,
   abstract = {Causal probabilistic networks (CPNs) have proved to be a useful knowledge representation tool for modeling domains where causal relations‐in a broad sense‐are a natural way of relating domain concepts and where uncertainty is inherited in these relations. The domain is modeled in a CPN by use of a directed graph where the nodes represent concepts in the domain and the arcs represent causal relations. Furthermore, the quantitative relation between a node and its immediate causes is expressed as conditional probabilities. During the last few years, several schemes based on probability theory for incorporating and propagating new information throughout a CPN has emerged. As long as the domain can be modeled by use of a singly connected CPN (i. e., no more than one path between any pair of nodes), the schemes operate directly in the CPN and perform conceptually simple operations in this structure. When it comes to more complicated structures such as multiply connected CPNs (i. e., more than one path is allowed between pairs of nodes), the schemes operate in derived structures where the embedded domain knowledge no longer is as explicit and transparent as in the CPN. Furthermore, the simplicity in the operations is lost also. This report outlines a scheme‐the algebra of Bayesian belief universes‐for absorbing and propagating evidence in multiply connected CPNs. The scheme provides a secondary structure, a junction tree, and a simple set of algebraic operations between objects in this structure, Collect Evidence and Distribute Evidence. These are the basic tools for making inference in a CPN domain model and yield a calculus as simple as in the case of singly connected CPNs. Copyright © 1990 Wiley Periodicals, Inc., A Wiley Company},
   author = {Finn Verner Jensen and Kristian G. Olesen and Stig Kjaer Andersen},
   doi = {10.1002/net.3230200509},
   issn = {10970037},
   issue = {5},
   journal = {Networks},
   pages = {637-659},
   title = {An algebra of bayesian belief universes for knowledge‐based systems},
   volume = {20},
   year = {1990},
}
@article{Bromley2005,
   abstract = {Integrated management is the key to the sustainable development of Europe's water resources. This means that decisions need to be taken in the light of not only environmental considerations, but also their economic, social, and political impacts; it also requires the active participation of stakeholders in the decision making process. The problem is to find a practical way to achieve these aims. One approach is to use Bayesian networks (Bns): networks allow a range of different factors to be linked together, based on probabilistic dependencies, and at the same time provide a framework within which the contributions of stakeholders can be taken into account. A further strength is that Bns explicitly include the element of uncertainty related to any strategy or decision. The links are based on whatever data are available. This may be an extensive data set, output from a model or, in the absence of data, can be based on expert opinion. Networks are being developed for four catchments in Europe as part of the MERIT project; these are in the UK, Denmark, Italy and Spain. In each case stakeholder groups are contributing to the design of the networks that are used as a focus for the consultation process. As an example, the application to water management of a UK basin is discussed. Crown Copyright © 2004 Published by Elsevier Ltd. All rights reserved.},
   author = {J. Bromley and N. A. Jackson and O. J. Clymer and A. M. Giacomello and F. V. Jensen},
   doi = {10.1016/j.envsoft.2003.12.021},
   issn = {13648152},
   issue = {2},
   journal = {Environmental Modelling and Software},
   keywords = {Bayesian network,Integrated water resource management,Stakeholder participation,Uncertainty},
   pages = {231-242},
   publisher = {Elsevier BV},
   title = {The use of Hugin® to develop Bayesian networks as an aid to integrated water resource planning},
   volume = {20},
   year = {2005},
}
@article{Borsuk2004,
   abstract = {A Bayesian network consists of a graphical structure and a probabilistic description of the relationships among variables in a system. The graphical structure explicitly represents cause-and-effect assumptions that allow a complex causal chain linking actions to outcomes to be factored into an articulated series of conditional relationships. Each of these relationships can then be independently quantified using a submodel suitable for the type and scale of information available. This approach is particularly useful for ecological modelling because predictable patterns may emerge at a variety of scales, necessitating a multiplicity of model forms. As an example, we describe a Bayesian network integrating models of the various processes involved in eutrophication in the Neuse River estuary, North Carolina. These models were developed using a range of methods, including: process-based models statistically fit to long-term monitoring data, Bayesian hierarchical modelling of cross-system data gathered from the literature, multivariate regression modelling of mesocosm experiments, and judgements elicited from scientific experts. The ability of the network to accommodate such a diversity of methods allowed for the prediction of policy-relevant ecosystem attributes not normally included in models of eutrophication. All of the submodels in the network include estimates of predictive uncertainty in the form of probability distributions which are propagated to model endpoints. Predictions expressed as probabilities give stakeholders and decision-makers a realistic appraisal of the chances of achieving desired outcomes under alternative nutrient management strategies. In general, the further down the causal chain a variable was, the greater the predictive uncertainty. This suggests that a compromise is necessary between policy relevance and predictive precision, and that, to select defensible environmental management strategies, public officials must adopt decision-making methods that deal explicitly with scientific uncertainty. © 2003 Elsevier B.V. All rights reserved.},
   author = {Mark E. Borsuk and Craig A. Stow and Kenneth H. Reckhow},
   doi = {10.1016/j.ecolmodel.2003.08.020},
   issn = {03043800},
   issue = {2-3},
   journal = {Ecological Modelling},
   keywords = {Bayesian statistics,Coastal eutrophication,Cross-scale modelling,Decision support,Graphical models,Risk analysis,Water quality},
   month = {4},
   pages = {219-239},
   title = {A Bayesian network of eutrophication models for synthesis, prediction, and uncertainty analysis},
   volume = {173},
   year = {2004},
}
@article{Kyrimi2021,
   abstract = {No comprehensive review of Bayesian networks (BNs) in healthcare has been published in the past, making it difficult to organize the research contributions in the present and identify challenges and neglected areas that need to be addressed in the future. This unique and novel scoping review of BNs in healthcare provides an analytical framework for comprehensively characterizing the domain and its current state. A literature search of health and health informatics literature databases using relevant keywords found 3810 articles that were reduced to 123. This was after screening out those presenting Bayesian statistics, meta-analysis or neural networks, as opposed to BNs and those describing the predictive performance of multiple machine learning algorithms, of which BNs were simply one type. Using the novel analytical framework, we show that: (1) BNs in healthcare are not used to their full potential; (2) a generic BN development process is lacking; (3) limitations exist in the way BNs in healthcare are presented in the literature, which impacts understanding, consensus towards systematic methodologies, practice and adoption; and (4) a gap exists between having an accurate BN and a useful BN that impacts clinical practice. This review highlights several neglected issues, such as restricted aims of BNs, ad hoc BN development methods, and the lack of BN adoption in practice and reveals to researchers and clinicians the need to address these problems. To map the way forward, the paper proposes future research directions and makes recommendations regarding BN development methods and adoption in practice.},
   author = {Evangelia Kyrimi and Scott McLachlan and Kudakwashe Dube and Mariana R. Neves and Ali Fahmi and Norman Fenton},
   doi = {10.1016/j.artmed.2021.102108},
   issn = {18732860},
   journal = {Artificial Intelligence in Medicine},
   keywords = {Bayesian networks,Clinical decision support,Healthcare,Scoping review,Survey},
   month = {7},
   pmid = {34127238},
   publisher = {Elsevier B.V.},
   title = {A comprehensive scoping review of Bayesian networks in healthcare: Past, present and future},
   volume = {117},
   year = {2021},
}
@article{Sun2018,
   abstract = {Synthetic population is a key input to agent-based urban/transportation microsimulation models. The objective of population synthesis is to reproduce the underlying statistical properties of real population based on available microsamples and marginal distributions. However, characterizing the joint associations among a large set of attributes is challenging because of the curse of dimensionality, in particular when attributes are organized in a hierarchical household-individual structure. In this paper, we use a hierarchical mixture model to characterize the joint distribution of both household and individual attributes. Based on this model, we propose a framework of generating representative household structures in population synthesis. The framework integrates three models: (1) probabilistic tensor factorization, (2) multilevel latent class model, and (3) rejection sampling. With this framework, one can generalize not only the associations of within- and cross-level attributes, but also reproduce structural relationships among household members (e.g., husband-wife). As a case study, we implement this framework based on the household interview travel survey (HITS) data of Singapore, and then use the inferred model to generate a synthetic population pool. This model demonstrates great potential in reproducing the underlying statistical distribution of real population. The generated synthetic population can serve as a replacement for census in developing agent-based models, with privacy and confidentiality being protected and preserved.},
   author = {Lijun Sun and Alexander Erath and Ming Cai},
   doi = {10.1016/j.trb.2018.06.002},
   issn = {01912615},
   journal = {Transportation Research Part B: Methodological},
   keywords = {Mixture model,Multilevel latent class,Population synthesis,Probabilistic tensor factorization},
   month = {8},
   pages = {199-212},
   publisher = {Elsevier Ltd},
   title = {A hierarchical mixture modeling framework for population synthesis},
   volume = {114},
   year = {2018},
}
@article{Joubert2018,
   abstract = {This article presents the procedure followed to generate complete synthetic populations from the South African National Census. The populations are accurate at both household and individual level, and were generated for nine major metropolitan and provincial areas. The disaggregate description of the population is useful in a variety of modelling contexts, especially if one wants to observe or study the distributional effects of, for example, policy measures. That is, studies in which equity and equality are of concern. The datasets are publicly available from https://doi.org/10.17632/dh4gcm7ckb.1.},
   author = {Johan W Joubert},
   doi = {10.17632/dh4gcm7ckb.1},
   title = {Synthetic populations of South African urban areas},
   url = {http://creativecommons.org/licenses/by/4.0/},
   year = {2018},
}
@article{Sun2015,
   abstract = {Agent-based micro-simulation models require a complete list of agents with detailed demographic/socioeconomic information for the purpose of behavior modeling and simulation. This paper introduces a new alternative for population synthesis based on Bayesian networks. A Bayesian network is a graphical representation of a joint probability distribution, encoding probabilistic relationships among a set of variables in an efficient way. Similar to the previously developed probabilistic approach, in this paper, we consider the population synthesis problem to be the inference of a joint probability distribution. In this sense, the Bayesian network model becomes an efficient tool that allows us to compactly represent/reproduce the structure of the population system and preserve privacy and confidentiality in the meanwhile. We demonstrate and assess the performance of this approach in generating synthetic population for Singapore, by using the Household Interview Travel Survey (HITS) data as the known test population. Our results show that the introduced Bayesian network approach is powerful in characterizing the underlying joint distribution, and meanwhile the overfitting of data can be avoided as much as possible.},
   author = {Lijun Sun and Alexander Erath},
   doi = {10.1016/j.trc.2015.10.010},
   issn = {0968090X},
   journal = {Transportation Research Part C: Emerging Technologies},
   keywords = {Agent-based model,Bayesian networks,Data-driven,Population synthesis},
   month = {12},
   pages = {49-62},
   publisher = {Elsevier Ltd},
   title = {A Bayesian network approach for population synthesis},
   volume = {61},
   year = {2015},
}
@misc{Su2013,
   abstract = {We review the applicability of Bayesian networks (BNs) for discovering relations between genes, environment, and disease. By translating probabilistic dependencies among variables into graphical models and vice versa, BNs provide a comprehensible and modular framework for representing complex systems. We first describe the Bayesian network approach and its applicability to understanding the genetic and environmental basis of disease. We then describe a variety of algorithms for learning the structure of a network from observational data. Because of their relevance to real-world applications, the topics of missing data and causal interpretation are emphasized. The BN approach is then exemplified through application to data from a population-based study of bladder cancer in New Hampshire, USA. For didactical purposes, we intentionally keep this example simple. When applied to complete data records, we find only minor differences in the performance and results of different algorithms. Subsequent incorporation of partial records through application of the EM algorithm gives us greater power to detect relations. Allowing for network structures that depart from a strict causal interpretation also enhances our ability to discover complex associations including gene-gene (epistasis) and gene-environment interactions. While BNs are already powerful tools for the genetic dissection of disease and generation of prognostic models, there remain some conceptual and computational challenges. These include the proper handling of continuous variables and unmeasured factors, the explicit incorporation of prior knowledge, and the evaluation and communication of the robustness of substantive conclusions to alternative assumptions and data manifestations. © 2013 Su et al.; licensee BioMed Central Ltd.},
   author = {Chengwei Su and Angeline Andrew and Margaret R. Karagas and Mark E. Borsuk},
   doi = {10.1186/1756-0381-6-6},
   issn = {17560381},
   issue = {1},
   journal = {BioData Mining},
   keywords = {Arsenic,Belief networks,Bioinformatics,Complex traits,Genetic epidemiology,SNP,Structural learning},
   title = {Using Bayesian networks to discover relations between genes, environment, and disease},
   volume = {6},
   year = {2013},
}
@misc{,
   title = {Handbook of Graphical Models},
}
@misc{Drton2017,
   abstract = {A graphical model is a statistical model that is associated with a graph whose nodes correspond to variables of interest. The edges of the graph reflect allowed conditional dependencies among the variables. Graphical models have computationally convenient factorization properties and have long been a valuable tool for tractable modeling of multivariate distributions. More recently, applications such as reconstructing gene regulatory networks from gene expression data have driven major advances in structure learning, that is, estimating the graph underlying a model. We review some of these advances and discuss methods such as the graphical lasso and neighborhood selection for undirected graphical models (or Markov random fields) and the PC algorithm and score-based search methods for directed graphical models (or Bayesian networks). We further review extensions that account for effects of latent variables and heterogeneous data sources.},
   author = {Mathias Drton and Marloes H. Maathuis},
   doi = {10.1146/annurev-statistics-060116-053803},
   issn = {2326831X},
   journal = {Annual Review of Statistics and Its Application},
   keywords = {Bayesian network,Graphical model,Markov random field,Model selection,Multivariate statistics,Network reconstruction},
   month = {3},
   pages = {365-393},
   publisher = {Annual Reviews Inc.},
   title = {Structure learning in graphical modeling},
   volume = {4},
   year = {2017},
}
@misc{Xiang1997,
   abstract = {In learning belief networks, the single link lookahead search is widely adopted to reduce the search space. We show that there exists a class of probabilistic domain models which displays a special pattern of dependency. We analyze the behavior of several learning algorithms using diierent scoring metrics such as the entropy, conditional independence, minimal description length and Bayesian metrics. We demonstrate that single link lookahead search procedures (employed in these algorithms) cannot learn these models correctly. Thus, when the underlying domain model actually belongs to this class, the use of a single link search procedure will result in learning of an incorrect model. This may lead to inference errors when the model is used. Our analysis suggests that if the prior knowledge about a domain does not rule out the possible existence of these models, a multi-link lookahead search or other heuristics should be used for the learning process.},
   author = {Yuanfei Xiang and Y Xiang and S K M Wong},
   title = {Critical Remarks on Single Link Search in Learning Belief Networks},
   url = {https://www.researchgate.net/publication/2405133},
   year = {1997},
}
@misc{Xiang1999,
   abstract = {Learning belief networks from large domains can be expensive even with single-link lookahead search (SLLS). Since a SLLS cannot learn correctly in a class of problem domains, multi-link lookahead search (MLLS) is needed which further increases the computational complexity. In our experiment, learning in some difficult domains over more than a dozen variables took days. In this paper, we study how to use parallelism to speed up SLLS for learning in large domains and to tackle the increased complexity of MLLS for learning in difficult domains. We propose a natural decomposition of the learning task for parallel processing. We investigate two strategies for job allocation among processors to further improve load balancing and efficiency of the parallel system. For learning from very large datasets, we present a regrouping of the available processors such that slow data access through the file system can be replaced by fast memory access. Experimental results in a distributed memory MIMD computer demonstrate the effectiveness of the proposed algorithms.},
   author = {Y Xiang and T Chu and Yike Guo and Robert Grossman},
   journal = {Data Mining and Knowledge Discovery},
   keywords = {belief networks,parallel implementation of data mining},
   pages = {315-339},
   title = {Parallel Learning of Belief Networks in Large and Difficult Domains},
   volume = {3},
   year = {1999},
}
@inbook{Heckerman2007,
   abstract = {Bayesian methods have been developed for learning Bayesian networks from data. Most of this work has concentrated on Bayesian networks interpreted as a representation of probabilistic conditional independence without considering causation. Other researchers have shown that having a causal interpretation can be important because it allows us to predict the effects of interventions in a domain. In this chapter, we extend Bayesian methods for learning acausal Bayesian networks to causal Bayesian networks.},
   author = {David Heckerman},
   doi = {10.1017/CBO9780511611308.012},
   isbn = {9780511611308},
   journal = {Advances in Decision Analysis: From Foundations to Applications},
   month = {1},
   pages = {202-220},
   publisher = {Cambridge University Press},
   title = {A bayesian approach to learning causal networks},
   year = {2007},
}
@misc{,
   abstract = {This paper presents a procedure for the construction of probabilistic networks from a database of observations based on the minimum description length principle. On top of the advantages of the Bayesian approach the minimum description length principle offers the advantage that every probabilistic network structure that represents the same set of independencies gets assigned the same quality. This makes it is very suitable for the order.optimization procedure as described in [4]. Preliminary test results show that the algorithm performs comparable to the algorithm based on the Bayesian approach [6].},
   author = {Remco R Bouckaert},
   title = {Probabilistic Network Construction Using the Minimum Description Length PrinCiple},
}
@misc{Chickering2004,
   abstract = {In this paper, we provide new complexity results for algorithms that learn discrete-variable Bayesian networks from data. Our results apply whenever the learning algorithm uses a scoring criterion that favors the simplest structure for which the model is able to represent the generative distribution exactly. Our results therefore hold whenever the learning algorithm uses a consistent scoring criterion and is applied to a sufficiently large dataset. We show that identifying high-scoring structures is NP-hard, even when any combination of one or more of the following hold: the generative distribution is perfect with respect to some DAG containing hidden variables; we are given an independence oracle; we are given an inference oracle; we are given an information oracle; we restrict potential solutions to structures in which each node has at most k parents, for all k ≥ 3. Our proof relies on a new technical result that we establish in the appendices. In particular, we provide a method for constructing the local distributions in a Bayesian network such that the resulting joint distribution is provably perfect with respect to the structure of the network.},
   author = {David Maxwell Chickering and David Heckerman and Christopher Meek},
   journal = {Journal of Machine Learning Research},
   keywords = {NP-Hard,large-sample data,learning Bayesian networks,search complexity},
   pages = {1287-1330},
   title = {Large-Sample Learning of Bayesian Networks is NP-Hard},
   volume = {5},
   year = {2004},
}
@misc{Cooper1992,
   abstract = {This paper presents a Bayesian method for constructing probabilistic networks from databases. In particular , we focus on constructing Bayesian belief networks. Potential applications include computer-assisted hypothesis testing, automated scientific discovery, and automated construction of probabifistic expert systems. We extend the basic method to handle missing data and hidden (latent) variables. We show how to perform probahilistic inference by averaging over the inferences of multiple belief networks. Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases. Finally, we relate the methods in this paper to previous work, and we discuss open problems. Keywords. probabilistic networks, Bayesian belief networks, machine learning, induction 1. I n t r o d u c t i o n In this paper, we present a Bayesian method for constructing a probabilistic network from a database of records, which we call cases. Once constructed, such a network can provide insight into probabilistic dependencies that exist among the variables in the database. One application is the automated discovery of dependency relationships. The computer program searches for a probabilistic-network structure that has a high posterior probability given the database, and outputs the structure and its probability. A related task is computer-assisted hypothesis testing: The user enters a hypothetical structure of the dependency relationships among a set of variables, and the program calculates the probability of the structure given a database of cases on the variables. We can also construct a network and use it for computer-based diagnosis. For example, suppose we have a database in which a case contains data about the behavior of some system (i.e., findings). Suppose further that a case contains data about whether this particular behavior follows from proper system operation, or alternatively, is caused by one of several possible faults. Assume that the database contains many such cases from previous episodes of proper and faulty behavior. The method that we present in this paper can be used to construct from the database a probabilistic network that captures the probabilistic dependencies among findings and faults. Such a network then can be applied to classify future cases of system behavior by assigning a posterior probability to each of the possible faults and to the event "proper system operation." In this paper, we also shall discuss diagnostic inference that is based on combining the inferences of multiple alternative networks.},
   author = {Gregory E Cooper},
   pages = {309-347},
   title = {A Bayesian Method for the Induction of Probabilistic Networks from Data},
   volume = {9},
   year = {1992},
}
@article{Cai2016,
   abstract = {Bayesian network (BN) is a commonly used tool in probabilistic reasoning of uncertainty in industrial processes, but it requires modeling of large and complex systems, in situations such as fault diagnosis and reliability evaluation. Motivated by reduction of the overall complexities of BNs for fault diagnosis, and the reporting of faults that immediately occur, a real-time fault diagnosis methodology of complex systems with repetitive structures is proposed using object-oriented Bayesian networks (OOBNs). The modeling methodology consists of two main phases: an off-line OOBN construction phase and an on-line fault diagnosis phase. In the off-line phase, sensor historical data and expert knowledge are collected and processed to determine the faults and symptoms, and OOBN-based fault diagnosis models are developed subsequently. In the on-line phase, operator experience and sensor real-time data are placed in the OOBNs to perform the fault diagnosis. According to engineering experience, the judgment rules are defined to obtain the fault diagnosis results.},
   author = {Baoping Cai and Hanlin Liu and Min Xie},
   doi = {10.1016/j.ymssp.2016.04.019},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Complex systems,Fault diagnosis,Object-oriented Bayesian networks,Real-time},
   month = {12},
   pages = {31-44},
   publisher = {Academic Press},
   title = {A real-time fault diagnosis methodology of complex systems using object-oriented Bayesian networks},
   volume = {80},
   year = {2016},
}
@article{Kasper2012,
   abstract = {This article introduces a novel approach towards the recognition of typical driving maneuvers in structured highway scenarios and shows some key benefits of traffic scene modeling with object-oriented Bayesian networks (OOBNs). The approach exploits the advantages of an introduced lane-related coordinate system together with individual occupancy schedule grids for all modeled vehicles. This combination allows an efficient classification of the existing vehicle-lane and vehicle- vehicle relations in traffic scenes and thus substantially improves the understanding of complex traffic scenes. Probabilities and variances within the network are propagated systematically which results in probabilistic sets of the modeled driving maneuvers. Using this generic approach, the network is able to classify a total of 27 driving maneuvers including merging and object following.},
   author = {Dietmar Kasper and Galia Weidl and Thao Dang and Gabi Breuel and Andreas Tamke and Andreas Wedel and Wolfgang Rosenstiel},
   doi = {10.1109/mits.2012.2203229},
   issn = {1939-1390},
   issue = {3},
   journal = {IEEE Intelligent Transportation Systems Magazine},
   month = {8},
   pages = {19-31},
   publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
   title = {Object-Oriented Bayesian Networks for Detection of Lane Change Maneuvers},
   volume = {4},
   year = {2012},
}
@inproceedings{Weber2006,
   abstract = {Nowadays, the complex manufacturing processes have to be dynamically modelled and controlled to optimise the diagnosis and the maintenance policies. This article presents a methodology that will help developing Dynamic Object Oriented Bayesian Networks (DOOBNs) to formalise such complex dynamic models. The goal is to have a general reliability evaluation of a manufacturing process, from its implementation to its operating phase. The added value of this formalisation methodology consists in using the a priori knowledge of both the system's functioning and malfunctioning. Networks are built on principles of adaptability and integrate uncertainties on the relationships between causes and effects. Thus, the purpose is to evaluate, in terms of reliability, the impact of several decisions on the maintenance of the system. This methodology has been tested, in an industrial context, to model the reliability of a water (immersion) heater system. © 2005 Elsevier Ltd. All rights reserved.},
   author = {Philippe Weber and Lionel Jouffe},
   doi = {10.1016/j.ress.2005.03.006},
   issn = {09518320},
   issue = {2},
   journal = {Reliability Engineering and System Safety},
   keywords = {Dynamic Object Oriented Bayesian Networks (DOOBNs),Markov Chain,Reliability estimation},
   month = {2},
   pages = {149-162},
   title = {Complex system reliability modelling with Dynamic Object Oriented Bayesian Networks (DOOBN)},
   volume = {91},
   year = {2006},
}
@misc{,
   abstract = {Learning disentanglement aims at finding a low dimensional representation which consists of multiple explanatory and generative factors of the observational data. The framework of variational autoencoder (VAE) is commonly used to disentangle independent factors from observations. However, in real scenarios, factors with semantics are not necessarily independent. Instead, there might be an underlying causal structure which renders these factors dependent. We thus propose a new VAE based framework named CausalVAE, which includes a Causal Layer to transform independent exogenous factors into causal endogenous ones that correspond to causally related concepts in data. We further analyze the model identifiabitily, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments are conducted on various datasets, including synthetic and real word benchmark CelebA. Results show that the causal representations learned by CausalVAE are semantically interpretable, and their causal relationship as a Directed Acyclic Graph (DAG) is identified with good accuracy. Furthermore, we demonstrate that the proposed CausalVAE model is able to generate counterfactual data through "do-operation" to the causal factors.},
   author = {Mengyue Yang and Furui Liu and Zhitang Chen and Xinwei Shen and Jianye Hao and Jun Wang},
   title = {CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models},
}
@article{,
   title = {報告書},
}
@article{,
   abstract = {The measure of the equitable and sustainable well-being (Bes) is of growing interest in the last years. The National Institute of Statistics (Istat) provides, for Italy, a wide set of indicators describing each domain of well-being that is, by definition, a multidimensional concept. In this study, we propose the use of Bayesian networks to deal with basic and composite Bes indicators. Its capability to model very complex multivariate dependence structures is useful to describe the relationships between indicators belonging to different domains and, being a probabilistic expert system, the estimated network could be also useful for probabilistic inference and what-if analysis. In this study, all the Bayesian networks structures have been estimated by means of the hill climbing algorithm based on bootstrap resampling and model averaging in order to prevent bias due to deviations from the normality assumption.},
   author = {Pierpaolo D’Urso and Vincenzina Vitale},
   doi = {10.1007/s11205-020-02401-z},
   issn = {15730921},
   issue = {3},
   journal = {Social Indicators Research},
   keywords = {Bayesian networks,Bootstrap resampling,Equitable and sustainable well-being,Structural learning},
   month = {10},
   pages = {897-919},
   publisher = {Springer Science+Business Media B.V.},
   title = {Bayesian Networks Model Averaging for Bes Indicators},
   volume = {151},
   year = {2020},
}
@misc{,
   abstract = {For classification problems, Bayesian networks are often used to infer a class variable when given feature variables. Earlier reports have described that the classification accuracy of Bayesian network structures achieved by maximizing the marginal likelihood (ML) is lower than that achieved by maximizing the conditional log likelihood (CLL) of a class variable given the feature variables. However, the performance of Bayesian network structures achieved by maximizing ML is not necessarily worse than that achieved by maximizing CLL for large data because ML has asymptotic consistency. As the sample size becomes small, however, the error of learning structures by maximizing the ML becomes rapidly large; it then degrades the classification accuracy. As a method to resolve this shortcoming, model averaging, which marginalizes the class variable posterior over all structures, has been proposed. However, the posterior standard error of the structures in the model averaging becomes large as the sample size becomes small; it subsequently degrades the classification accuracy. The main idea of this study is to improve the classification accuracy using the subbagging to reduce the posterior standard error of the structures in the model averaging. Moreover, to guarantee asymptotic consistency, we use the K-best method with the ML score. The experimentally obtained results demonstrate that our proposed method provides more accurate classification for small data than earlier methods do.},
   author = {Shouta Sugahara and Itsuki Aomi and Maomi Ueno},
   keywords = {Bayesian networks,classification,model averaging,structure learning},
   title = {Bayesian Network Model Averaging Classifiers by Subbagging},
}
@misc{Cooper2004,
   abstract = {In this paper 1 we consider the problem of performing Bayesian model-averaging over a class of discrete Bayesian network structures consistent with a partial ordering and with bounded in-degree k. We show that for N nodes this class contains in the worst-case at least Ω(N/2 k N/2) distinct network structures, and yet model averaging over these structures can be performed using O(N k · N) operations. Furthermore we show that there exists a single Bayesian network that defines a joint distribution over the variables that is equivalent to model averaging over these structures. Although constructing this network is computationally prohibitive, we show that it can be approximated by a tractable network, allowing approximate model-averaged probability calculations to be performed in O(N) time. Our result also leads to an exact and linear-time solution to the problem of averaging over the 2 N possible feature sets in a naïve Bayes model, providing an exact Bayesian solution to the troublesome feature-selection problem for naïve Bayes classifiers. We demonstrate the utility of these techniques in the context of supervised classification, showing empirically that model averaging consistently beats other generative Bayesian-network-based models, even when the generating model is not guaranteed to be a member of the class being averaged over. We characterize the performance over several parameters on simulated and real-world data.},
   author = {Gregory F Cooper},
   journal = {Journal of Machine Learning Research},
   keywords = {Bayesian model averaging,Bayesian networks,classification,feature selection,naïve Bayes classifiers},
   pages = {1177-1203},
   title = {Model Averaging for Prediction with Discrete Bayesian Networks Denver Dash},
   volume = {5},
   year = {2004},
}
@article{Liao2020,
   abstract = {A Bayesian network is a widely used probabilistic graphical model with applications in knowledge discovery and prediction. Learning a Bayesian network (BN) from data can be cast as an optimization problem using the well-known score-and-search approach. However, selecting a single model (i.e., the best scoring BN) can be misleading or may not achieve the best possible accuracy. An alternative to committing to a single model is to perform some form of Bayesian or frequentist model averaging, where the space of possible BNs is sampled or enumerated in some fashion. Unfortunately, existing approaches for model averaging either severely restrict the structure of the Bayesian network or have only been shown to scale to networks with fewer than 30 random variables. In this paper, we propose a novel approach to model averaging inspired by performance guarantees in approximation algorithms. Our approach has two primary advantages. First, our approach only considers credible models in that they are optimal or near-optimal in score. Second, our approach is more efficient and scales to significantly larger Bayesian networks than existing approaches.},
   author = {Zhenyu A. Liao and Charupriya Sharma and James Cussens and Peter van Beek},
   month = {8},
   title = {Learning All Credible Bayesian Network Structures for Model Averaging},
   url = {http://arxiv.org/abs/2008.13618},
   year = {2020},
}
@article{Broom2012,
   abstract = {Considerable progress has been made on algorithms for learning the structure of Bayesian networks from data. Model averaging by using bootstrap replicates with feature selection by thresholding is a widely used solution for learning features with high confidence. Yet, in the context of limited data many questions remain unanswered. What scoring functions are most effective for model averaging? Does the bias arising from the discreteness of the bootstrap significantly affect learning performance? Is it better to pick the single best network or to average multiple networks learnt from each bootstrap resample? How should thresholds for learning statistically significant features be selected? The best scoring functions are Dirichlet Prior Scoring Metric with small λ and the Bayesian Dirichlet metric. Correcting the bias arising from the discreteness of the bootstrap worsens learning performance. It is better to pick the single best network learnt from each bootstrap resample. We describe a permutation based method for determining significance thresholds for feature selection in bagged models. We show that in contexts with limited data, Bayesian bagging using the Dirichlet Prior Scoring Metric (DPSM) is the most effective learning strategy, and that modifying the scoring function to penalize complex networks hampers model averaging. We establish these results using a systematic study of two well-known benchmarks, specifically ALARM and INSURANCE. We also apply our network construction method to gene expression data from the Cancer Genome Atlas Glioblastoma multiforme dataset and show that survival is related to clinical covariates age and gender and clusters for interferon induced genes and growth inhibition genes. For small data sets, our approach performs significantly better than previously published methods.},
   author = {Bradley M. Broom and Kim Anh Do and Devika Subramanian},
   doi = {10.1186/1471-2105-13-S13-S10},
   issn = {14712105},
   journal = {BMC bioinformatics},
   pmid = {23320818},
   title = {Model averaging strategies for structure learning in Bayesian networks with limited data.},
   volume = {13 Suppl 13},
   year = {2012},
}
@article{Sugahara2022,
   abstract = {When applied to classification problems, Bayesian networks are often used to infer a class variable when given feature variables. Earlier reports have described that the classification accuracy of Bayesian network structures achieved by maximizing the marginal likelihood (ML) is lower than that achieved by maximizing the conditional log likelihood (CLL) of a class variable given the feature variables. Nevertheless, because ML has asymptotic consistency, the performance of Bayesian network structures achieved by maximizing ML is not necessarily worse than that achieved by maximizing CLL for large data. However, the error of learning structures by maximizing the ML becomes much larger for small sample sizes. That large error degrades the classification accuracy. As a method to resolve this shortcoming, model averaging has been proposed to marginalize the class variable posterior over all structures. However, the posterior standard error of each structure in the model averaging becomes large as the sample size becomes small; it subsequently degrades the classification accuracy. The main idea of this study is to improve the classification accuracy using subbagging, which is modified bagging using random sampling without replacement, to reduce the posterior standard error of each structure in model averaging. Moreover, to guarantee asymptotic consistency, we use the K-best method with the ML score. The experimentally obtained results demonstrate that our proposed method provides more accurate classification than earlier BNC methods and the other state-of-the-art ensemble methods do.},
   author = {Shouta Sugahara and Itsuki Aomi and Maomi Ueno},
   doi = {10.3390/e24050743},
   issn = {10994300},
   issue = {5},
   journal = {Entropy},
   keywords = {Bayesian networks,classification,model averaging,structure learning},
   month = {5},
   publisher = {MDPI},
   title = {Bayesian Network Model Averaging Classifiers by Subbagging},
   volume = {24},
   year = {2022},
}
@misc{Scanagatta2019,
   abstract = {A necessary step in the development of artificial intelligence is to enable a machine to represent how the world works, building an internal structure from data. This structure should hold a good trade-off between expressive power and querying efficiency. Bayesian networks have proven to be an effective and versatile tool for the task at hand. They have been applied to modeling knowledge in a variety of fields, ranging from bioinformatics to law, from image processing to economic risk analysis. A crucial aspect is learning the dependency graph of a Bayesian network from data. This task, called structure learning, is NP-hard and is the subject of intense, cutting-edge research. In short, it can be thought of as choosing one graph over the many candidates, grounding our reasoning over a collection of samples of the distribution generating the data. The number of possible graphs increases very quickly at the increase in the number of variables. Searching in this space, and selecting a graph over the others, becomes quickly burdensome. In this survey, we review the most relevant structure learning algorithms that have been proposed in the literature. We classify them according to the approach they follow for solving the problem and we also show alternatives for handling missing data and continuous variable. An extensive review of existing software tools is also given.},
   author = {Mauro Scanagatta and Antonio Salmerón and Fabio Stella},
   doi = {10.1007/s13748-019-00194-y},
   issn = {21926360},
   issue = {4},
   journal = {Progress in Artificial Intelligence},
   keywords = {Bayesian network,Machine learning,Statistics,Structure learning},
   month = {12},
   pages = {425-439},
   publisher = {Springer Verlag},
   title = {A survey on Bayesian network structure learning from data},
   volume = {8},
   year = {2019},
}
@article{Daly2011,
   abstract = {Bayesian networks have become a widely used method in the modelling of uncertain knowledge. Owing to the difficulty domain experts have in specifying them, techniques that learn Bayesian networks from data have become indispensable. Recently, however, there have been many important new developments in this field. This work takes a broad look at the literature on learning Bayesian networks-in particular their structure-from data. Specific topics are not focused on in detail, but it is hoped that all the major fields in the area are covered. This article is not intended to be a tutorial-for this, there are many books on the topic, which will be presented. However, an effort has been made to locate all the relevant publications, so that this paper can be used as a ready reference to find the works on particular sub-topics. © 2011 Cambridge University Press.},
   author = {Rónán Daly and Qiang Shen and Stuart Aitken},
   doi = {10.1017/S0269888910000251},
   issn = {02698889},
   issue = {2},
   journal = {Knowledge Engineering Review},
   month = {6},
   pages = {99-157},
   title = {Learning Bayesian networks: Approaches and issues},
   volume = {26},
   year = {2011},
}
@misc{,
   abstract = {One of the basic tasks for Bayesian networks (BNs) is that of learning a network structure from data. The BN-learning problem is NP-hard, so the standard solution is heuristic search. Many approaches have been proposed for this task, but only a very small number outperform the baseline of greedy hill-climbing with tabu lists; moreover, many of the proposed algorithms are quite complex and hard to implement. In this paper, we propose a very simple and easy-to-implement method for addressing this task. Our approach is based on the well-known fact that the best network (of bounded in-degree) consistent with a given node ordering can be found very efficiently. We therefore propose a search not over the space of structures, but over the space of orderings, selecting for each ordering the best network consistent with it. This search space is much smaller, makes more global search steps, has a lower branching factor, and avoids costly acyclicity checks. We present results for this algorithm on both synthetic and real data sets, evaluating both the score of the network found and in the running time. We show that ordering-based search outperforms the standard baseline, and is competitive with recent algorithms that are much harder to implement.},
   author = {Marc Teyssier and Daphne Koller},
   title = {Ordering-Based Search: A Simple and Effective Algorithm for Learning Bayesian Networks},
}
@article{Wang2021,
   abstract = {It is a long-standing question to discover causal relations among a set of variables in many empirical sciences. Recently, Reinforcement Learning (RL) has achieved promising results in causal discovery from observational data. However, searching the space of directed graphs and enforcing acyclicity by implicit penalties tend to be inefficient and restrict the existing RL-based method to small scale problems. In this work, we propose a novel RL-based approach for causal discovery, by incorporating RL into the ordering-based paradigm. Specifically, we formulate the ordering search problem as a multi-step Markov decision process, implement the ordering generating process with an encoder-decoder architecture, and finally use RL to optimize the proposed model based on the reward mechanisms designed for~each ordering. A generated ordering would then be processed using variable selection to obtain the final causal graph. We analyze the consistency and computational complexity of the proposed method, and empirically show that a pretrained model can be exploited to accelerate training. Experimental results on both synthetic and real data sets shows that the proposed method achieves a much improved performance over existing RL-based method.},
   author = {Xiaoqiang Wang and Yali Du and Shengyu Zhu and Liangjun Ke and Zhitang Chen and Jianye Hao and Jun Wang},
   month = {5},
   title = {Ordering-Based Causal Discovery with Reinforcement Learning},
   url = {http://arxiv.org/abs/2105.06631},
   year = {2021},
}
@article{Marella2014,
   abstract = {In this paper we propose to use the object-oriented Bayesian network (OOBN) architecture to model measurement errors. We then apply our model to the Italian survey on household income and wealth (SHIW) 2008. Attention is focused on errors caused by the respondents. The parameters of the error model are estimated using a validation sample. The network is used to stochastically impute micro data for households. In particular imputation is performed also using an auxiliary variable. Indices are calculated to evaluate the performance of the correction procedure and show that accounting for auxiliary information improves the results. Finally, potentialities and possible extensions of the Bayesian network approach both to the measurement error context and to official statistics problems in general are discussed.},
   author = {Daniela Marella and Paola Vicard},
   doi = {10.1007/978-3-319-05320-2__9},
   keywords = {Bayesian networks,Measurement error,Respondent error},
   title = {Modelling Measurement Errors by Object-Oriented Bayesian Networks: An Application to 2008 SHIW},
   year = {2014},
}
@article{Musella2015,
   abstract = {Quality management and customer satisfaction evaluation can be difficult tasks to perform when processes involve multiple production lines or provide multichannel services. As a consequence, the top management needs to analyse the problem from different perspectives, to evaluate possible improvement strategies at several levels and to take appropriate decisions. To this aim, we propose to use object-oriented Bayesian networks by which different quality aspects and evaluations can be integrated in a unique framework allowing to analyse improvement strategies in real time. We show, by an application to an internal-customer satisfaction survey, how to combine the perceived quality of different production areas and how to evaluate the impact on the global quality of improvement actions developed in one or more areas.},
   author = {Flaminia Musella and Paola Vicard},
   doi = {10.1007/s11135-013-9977-3},
   issn = {15737845},
   issue = {1},
   journal = {Quality and Quantity},
   keywords = {Bayesian networks,Decision making,Global quality evaluation,What-if analysis},
   month = {1},
   pages = {115-133},
   publisher = {Springer Netherlands},
   title = {Object-oriented Bayesian networks for complex quality management problems},
   volume = {49},
   year = {2015},
}
@misc{,
   abstract = {Bayesian networks provide a modeling language and associated inference algorithm for stochastic domains. They have been successfully applied in a variety of medium-scale applications. However, when faced with a large complex domain, the task of modeling using Bayesian networks begins to resemble the task of pro­ gramming using logical circuits. In this paper, we de­ scribe an object-oriented Bayesian network (OOBN) lan­ guage, which allows complex domains to be described in terms of interrelated objects. We use a Bayesian net­ work fragment to describe the probabilistic relations be­ tween the attributes of an object. These attributes can themsel ves be objects, providing a natural framework for encoding part-of hierarchies. Classes are used to pro­ vide a reusable probabilistic model which can be applied to multiple similar objects. Classes also support inher­ itance of model fragments from a class to a subclass, allowing the common aspects of related classes to be defined only once. Our language has clear declarative semantics: an OOBN can be interpreted as a stochas­ tic functional program, so that it uniquely specifies a probabilistic model. We provide an inference algorithm for OOBNs, and show that much of the structural infor­ mation encoded by an OOBN-particularly the encap­ sulation of variables within an object and the reuse of model fragments in different contexts-can also be used to speed up the inference process.},
   author = {Daphne Koller},
   title = {Object-Oriented Bayesian Networks},
}
@misc{,
   abstract = {Recently several researchers have investigated techniques for using data to learn Bayesian networks containing compact representations for the conditional probability distributions (CPDs) stored at each node. The majority of this work has concentrated on using decision-tree representations for the CPDs. In addition, researchers typically apply non-Bayesian (or asymptotically Bayesian) scoring functions such as MDL to evaluate the goodness-of-fit of networks to the data. In this paper we investigate a Bayesian approach to learning Bayesian networks that contain the more general decision-graph representations of the CPDs. First, we describe how to evaluate the posterior probability-that is, the Bayesian score-of such a network , given a database of observed cases. Second, we describe various search spaces that can be used, in conjunction with a scoring function and a search procedure, to identify one or more high-scoring networks. Finally , we present an experimental evaluation of the search spaces, using a greedy algorithm and a Bayesian scoring function.},
   author = {David Maxwell Chickering and David Heckerman},
   title = {A Bayesian Approach to Learning Bayesian Networks with Local Structure},
}
@misc{,
   author = {M Jordan and J Kleinberg and B Schölkopf},
   title = {Information Science and Statistics},
}
@article{Lachapelle2019,
   abstract = {We propose a novel score-based approach to learning a directed acyclic graph (DAG) from observational data. We adapt a recently proposed continuous constrained optimization formulation to allow for nonlinear relationships between variables using neural networks. This extension allows to model complex interactions while avoiding the combinatorial nature of the problem. In addition to comparing our method to existing continuous optimization methods, we provide missing empirical comparisons to nonlinear greedy search methods. On both synthetic and real-world data sets, this new method outperforms current continuous methods on most tasks, while being competitive with existing greedy search methods on important metrics for causal inference.},
   author = {Sébastien Lachapelle and Philippe Brouillard and Tristan Deleu and Simon Lacoste-Julien},
   month = {6},
   title = {Gradient-Based Neural DAG Learning},
   url = {http://arxiv.org/abs/1906.02226},
   year = {2019},
}
@article{Zhang2019,
   abstract = {Graph structured data are abundant in the real world. Among different graph types, directed acyclic graphs (DAGs) are of particular interest to machine learning researchers, as many machine learning models are realized as computations on DAGs, including neural networks and Bayesian networks. In this paper, we study deep generative models for DAGs, and propose a novel DAG variational autoencoder (D-VAE). To encode DAGs into the latent space, we leverage graph neural networks. We propose an asynchronous message passing scheme that allows encoding the computations on DAGs, rather than using existing simultaneous message passing schemes to encode local graph structures. We demonstrate the effectiveness of our proposed DVAE through two tasks: neural architecture search and Bayesian network structure learning. Experiments show that our model not only generates novel and valid DAGs, but also produces a smooth latent space that facilitates searching for DAGs with better performance through Bayesian optimization.},
   author = {Muhan Zhang and Shali Jiang and Zhicheng Cui and Roman Garnett and Yixin Chen},
   month = {4},
   title = {D-VAE: A Variational Autoencoder for Directed Acyclic Graphs},
   url = {http://arxiv.org/abs/1904.11088},
   year = {2019},
}
@article{,
   title = {DBN},
}
@article{Zheng2018,
   abstract = {Estimating the structure of directed acyclic graphs (DAGs, also known as Bayesian networks) is a challenging problem since the search space of DAGs is combinatorial and scales superexponentially with the number of nodes. Existing approaches rely on various local heuristics for enforcing the acyclicity constraint. In this paper, we introduce a fundamentally different strategy: We formulate the structure learning problem as a purely \emph\{continuous\} optimization problem over real matrices that avoids this combinatorial constraint entirely. This is achieved by a novel characterization of acyclicity that is not only smooth but also exact. The resulting problem can be efficiently solved by standard numerical algorithms, which also makes implementation effortless. The proposed method outperforms existing ones, without imposing any structural assumptions on the graph such as bounded treewidth or in-degree. Code implementing the proposed algorithm is open-source and publicly available at https://github.com/xunzheng/notears.},
   author = {Xun Zheng and Bryon Aragam and Pradeep Ravikumar and Eric P. Xing},
   month = {3},
   title = {DAGs with NO TEARS: Continuous Optimization for Structure Learning},
   url = {http://arxiv.org/abs/1803.01422},
   year = {2018},
}
@misc{,
   abstract = {We propose a new differentiable probabilistic model over DAGs (DP-DAG). DP-DAG allows fast and differentiable DAG sampling suited to continuous optimization. To this end, DP-DAG samples a DAG by successively (1) sampling a linear ordering of the node and (2) sampling edges consistent with the sampled linear ordering. We further propose VI-DP-DAG, a new method for DAG learning from observational data which combines DP-DAG with variational inference. Hence, VI-DP-DAG approximates the posterior probability over DAG edges given the observed data. VI-DP-DAG is guaranteed to output a valid DAG at any time during training and does not require any complex augmented Lagrangian optimization scheme in contrast to existing differentiable DAG learning approaches. In our extensive experiments, we compare VI-DP-DAG to other differentiable DAG learning baselines on synthetic and real datasets. VI-DP-DAG significantly improves DAG structure and causal mechanism learning while training faster than competitors.},
   author = {Bertrand Charpentier and Simon Kibler and Stephan Günnemann},
   title = {DIFFERENTIABLE DAG SAMPLING},
}
@article{Yu2019,
   abstract = {Learning a faithful directed acyclic graph (DAG) from samples of a joint distribution is a challenging combinatorial problem, owing to the intractable search space superexponential in the number of graph nodes. A recent breakthrough formulates the problem as a continuous optimization with a structural constraint that ensures acyclicity (Zheng et al., 2018). The authors apply the approach to the linear structural equation model (SEM) and the least-squares loss function that are statistically well justified but nevertheless limited. Motivated by the widespread success of deep learning that is capable of capturing complex nonlinear mappings, in this work we propose a deep generative model and apply a variant of the structural constraint to learn the DAG. At the heart of the generative model is a variational autoencoder parameterized by a novel graph neural network architecture, which we coin DAG-GNN. In addition to the richer capacity, an advantage of the proposed model is that it naturally handles discrete variables as well as vector-valued ones. We demonstrate that on synthetic data sets, the proposed method learns more accurate graphs for nonlinearly generated samples; and on benchmark data sets with discrete variables, the learned graphs are reasonably close to the global optima. The code is available at \url\{https://github.com/fishmoon1234/DAG-GNN\}.},
   author = {Yue Yu and Jie Chen and Tian Gao and Mo Yu},
   month = {4},
   title = {DAG-GNN: DAG Structure Learning with Graph Neural Networks},
   url = {http://arxiv.org/abs/1904.10098},
   year = {2019},
}
@article{Vowels2021,
   abstract = {Causal reasoning is a crucial part of science and human intelligence. In order to discover causal relationships from data, we need structure discovery methods. We provide a review of background theory and a survey of methods for structure discovery. We primarily focus on modern, continuous optimization methods, and provide reference to further resources such as benchmark datasets and software packages. Finally, we discuss the assumptive leap required to take us from structure to causality.},
   author = {Matthew J. Vowels and Necati Cihan Camgoz and Richard Bowden},
   month = {3},
   title = {D'ya like DAGs? A Survey on Structure Learning and Causal Discovery},
   url = {http://arxiv.org/abs/2103.02582},
   year = {2021},
}
@article{Kitson2023,
   abstract = {Bayesian Networks (BNs) have become increasingly popular over the last few decades as a tool for reasoning under uncertainty in fields as diverse as medicine, biology, epidemiology, economics and the social sciences. This is especially true in real-world areas where we seek to answer complex questions based on hypothetical evidence to determine actions for intervention. However, determining the graphical structure of a BN remains a major challenge, especially when modelling a problem under causal assumptions. Solutions to this problem include the automated discovery of BN graphs from data, constructing them based on expert knowledge, or a combination of the two. This paper provides a comprehensive review of combinatoric algorithms proposed for learning BN structure from data, describing 74 algorithms including prototypical, well-established and state-of-the-art approaches. The basic approach of each algorithm is described in consistent terms, and the similarities and differences between them highlighted. Methods of evaluating algorithms and their comparative performance are discussed including the consistency of claims made in the literature. Approaches for dealing with data noise in real-world datasets and incorporating expert knowledge into the learning process are also covered.},
   author = {Neville Kenneth Kitson and Anthony C. Constantinou and Zhigao Guo and Yang Liu and Kiattikun Chobtham},
   doi = {10.1007/s10462-022-10351-w},
   issn = {15737462},
   issue = {8},
   journal = {Artificial Intelligence Review},
   keywords = {Causal discovery,Graphical models,Knowledge-based constraints,Structure learning evaluation,Structure learning review},
   month = {8},
   pages = {8721-8814},
   publisher = {Springer Nature},
   title = {A survey of Bayesian Network structure learning},
   volume = {56},
   year = {2023},
}
@misc{Marcot2019,
   abstract = {Bayesian network (BN) modeling is a rapidly advancing field. Here we explore new methods by which BN model development and application are being joined with other tools and model frameworks. Advances include improving areas of Bayesian classifiers and machine-learning algorithms for model structuring and parameterization, and development of time-dynamic models. Increasingly, BN models are being integrated with: management decision networks; structural equation modeling of causal networks; Bayesian neural networks; combined discrete and continuous variables; object-oriented and agent-based models; state-and-transition models; geographic information systems; quantum probability; and other fields. Integrated BNs (IBNs) are becoming useful tools in risk analysis, risk management, and decision science for resource planning and environmental management. In the near future, IBNs may become self-structuring, self-learning systems fed by real-time monitoring data. Such advances may make model validation difficult, and may question model credibility, particularly if based on uncertain sources of knowledge systems and big data.},
   author = {Bruce G. Marcot and Trent D. Penman},
   doi = {10.1016/j.envsoft.2018.09.016},
   issn = {13648152},
   journal = {Environmental Modelling and Software},
   keywords = {Bayesian networks,Decision models,Machine learning,Model integration,Model validation},
   month = {1},
   pages = {386-393},
   publisher = {Elsevier Ltd},
   title = {Advances in Bayesian network modelling: Integration of modelling technologies},
   volume = {111},
   year = {2019},
}
@misc{,
   abstract = {We present a method for learning Bayesian networks from data sets containing thousands of variables without the need for structure constraints. Our approach is made of two parts. The first is a novel algorithm that effectively explores the space of possible parent sets of a node. It guides the exploration towards the most promising parent sets on the basis of an approximated score function that is computed in constant time. The second part is an improvement of an existing ordering-based algorithm for structure optimization. The new algorithm provably achieves a higher score compared to its original formulation. Our novel approach consistently outperforms the state of the art on very large data sets.},
   author = {Mauro Scanagatta and Giorgio Corani and Marco Zaffalon},
   title = {Learning Bayesian Networks with Thousands of Variables},
   url = {http://www.cs.york.ac.uk/aig/sw/gobnilp/},
}
@misc{Cooper1992,
   abstract = {This paper presents a Bayesian method for constructing probabilistic networks from databases. In particular , we focus on constructing Bayesian belief networks. Potential applications include computer-assisted hypothesis testing, automated scientific discovery, and automated construction of probabifistic expert systems. We extend the basic method to handle missing data and hidden (latent) variables. We show how to perform probahilistic inference by averaging over the inferences of multiple belief networks. Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases. Finally, we relate the methods in this paper to previous work, and we discuss open problems. Keywords. probabilistic networks, Bayesian belief networks, machine learning, induction 1. I n t r o d u c t i o n In this paper, we present a Bayesian method for constructing a probabilistic network from a database of records, which we call cases. Once constructed, such a network can provide insight into probabilistic dependencies that exist among the variables in the database. One application is the automated discovery of dependency relationships. The computer program searches for a probabilistic-network structure that has a high posterior probability given the database, and outputs the structure and its probability. A related task is computer-assisted hypothesis testing: The user enters a hypothetical structure of the dependency relationships among a set of variables, and the program calculates the probability of the structure given a database of cases on the variables. We can also construct a network and use it for computer-based diagnosis. For example, suppose we have a database in which a case contains data about the behavior of some system (i.e., findings). Suppose further that a case contains data about whether this particular behavior follows from proper system operation, or alternatively, is caused by one of several possible faults. Assume that the database contains many such cases from previous episodes of proper and faulty behavior. The method that we present in this paper can be used to construct from the database a probabilistic network that captures the probabilistic dependencies among findings and faults. Such a network then can be applied to classify future cases of system behavior by assigning a posterior probability to each of the possible faults and to the event "proper system operation." In this paper, we also shall discuss diagnostic inference that is based on combining the inferences of multiple alternative networks.},
   author = {Gregory E Cooper},
   pages = {309-347},
   title = {A Bayesian Method for the Induction of Probabilistic Networks from Data},
   volume = {9},
   year = {1992},
}
@inproceedings{Sallard2023,
   abstract = {Thanks to their ability to simulate the travel behavior at the individual scale, agent-based models have gained popularity over the last years. These models are data-intensive, with regards to transport supply and demand. In particular, a detailed description of the population and its travel behavior is required. Bayesian Networks (BNs) are directed acyclic graphs representing joint probability distributions. They have recently been employed for population synthesis and daily activity patterns generation in studies showing that BNs effectively capture the causality links existing between variables and are easily interpretable. Moreover, given their flexible structure, BNs can be adapted for situations in which data from various sources is combined. In this paper, our goal is to estimate a BN for both population and activity pattern synthesis in Switzerland. We evaluate the performance of this approach compared to the statistical matching algorithm using aggregated and disaggregated metrics. In particular, we show that understanding the dependency structure linking the population characteristics and its mobility behavior is key to generate representative synthetic agents and daily activity patterns. This study is a contribution towards the development of interpretable, flexible and behaviorally rich travel demand generation models.},
   author = {Aurore Sallard and Miloš Balac},
   doi = {10.1016/j.procs.2023.03.035},
   issn = {18770509},
   journal = {Procedia Computer Science},
   keywords = {Activity-based models,Bayesian networks,Synthetic Population,Travel demand generation},
   pages = {267-274},
   publisher = {Elsevier B.V.},
   title = {Travel demand generation using Bayesian Networks: An application to Switzerland},
   volume = {220},
   year = {2023},
}
@article{,
   abstract = {To deal with increasing amounts of data, decision and policymakers frequently turn to advances in machine learning and artificial intelligence to capitalise on the potential reward. But there is also a reluctance to trust black-box models, especially when such models are used to support decisions and policies that affect people directly, like those associated with transport and people's mobility. Recent developments focus on explainable artificial intelligence to bolster models’ trustworthiness. In this paper, we demonstrate the use of an explainable-by-design model, Bayesian Networks, on travel behaviour. The model incorporates various demographic and socioeconomic variables to describe full day activity chains: activity and mode choice, as well as the activity and trip durations. More importantly, this paper shows how the model can be used to provide the most relevant explanation for people's observed travel behaviour. The overall goal is to show that model explanations can be quantified and, therefore, assist policymakers to truly make evidence-based decisions. This goal is achieved through two case studies to explain people's vulnerability as it pertains to their total trip duration.},
   author = {Alta de Waal and Johan W. Joubert},
   doi = {10.1016/j.eswa.2022.118348},
   issn = {09574174},
   journal = {Expert Systems with Applications},
   keywords = {Activity chain,Bayesian networks,Explainable artificial intelligence,Most relevant explanation},
   month = {12},
   publisher = {Elsevier Ltd},
   title = {Explainable Bayesian networks applied to transport vulnerability},
   volume = {209},
   year = {2022},
}
@article{Joubert2020,
   abstract = {While activity-based travel demand generation has improved over the last few decades, the behavioural richness and intuitive interpretation remain challenging. This paper argues that it is essential to understand why people travel the way they do and not only be able to predict the overall activity patterns accurately. If one cannot understand the “why?” then a model's ability to evaluate the impact of future interventions is severely diminished. Bayesian networks (BNs) provide the ability to investigate causality and is showing value in recent literature to generate synthetic populations. This paper is novel in extending the application of BNs to daily activity tours. Results show that BNs can synthesise both activity and trip chain structures accurately. It outperforms a frequentist approach and can cater for infrequently observed activity patterns, and patterns unobserved in small sample data. It can also account for temporal variables like activity duration.},
   author = {Johan W. Joubert and Alta de Waal},
   doi = {10.1016/j.trc.2020.102804},
   issn = {0968090X},
   journal = {Transportation Research Part C: Emerging Technologies},
   keywords = {Activity choice,Activity-based,Tour generation,Travel demand},
   month = {11},
   publisher = {Elsevier Ltd},
   title = {Activity-based travel demand generation using Bayesian networks},
   volume = {120},
   year = {2020},
}
@article{Ma2018,
   abstract = {In this work, we propose a Bayesian network approach by using structural restrictions and a model averaging algorithm for modeling the location choice of discretionary activities. In a first stage, we delimit individuals' location choice which is set by generating an ellipse that uses empirical detour factors and a homework axis. The choice set is further refined by an individual's space-time constraints in order to identify the constrained destination choice set. We use structural restrictions and a model averaging method to learn the network structure of the Bayesian network in order to predict the heuristics of individuals' location selection. The empirical study shows the proposed method can effectively obtain Bayesian networks with a consistent dependency structure. The empirical study suggests activity schedule factors significantly influence location choice decisions.},
   author = {Tai-Yu Ma and Sylvain Klein},
   issn = {1567-7141},
   issue = {1},
   journal = {EJTIR Issue},
   keywords = {Bayesian networks,Choice set generation,Location choice,Space-time behaviour,Structure learning},
   pages = {91-111},
   title = {Bayesian networks for constrained location choice modeling using structural restrictions and model averaging},
   volume = {18},
   url = {http://tlo.tbm.tudelft.nl/ejtir},
   year = {2018},
}
@article{Ma2017,
   abstract = {This work contributes to develop a new methodology to identify empirical-data-driven causal structure of a domain knowledge. We propose an algorithm as a two-stage procedure by first drawing relevant prior partial relationships between variables and using them as structure constraints in a structure learning task of Bayesian networks (BNs). The latter is then based on a model averaging approach to obtain a statistically sound BN. The empirical study focuses on modeling commuters' travel mode choice. We present experimental results on testing the design of prior restrictions, the effect of resampling size and learning algorithms, and the effect of random draw on fitted BN structure. The results show that the proposed method can capture more sophisticated relationships between the variables that are missing in both decision tree models and random utility models.},
   author = {Tai Yu Ma and Joseph Y.J. Chow and Jia Xu},
   doi = {10.1080/23249935.2016.1265019},
   issn = {23249943},
   issue = {4},
   journal = {Transportmetrica A: Transport Science},
   keywords = {Bayesian networks,causal structure,structure learning algorithm,travel mode choice},
   month = {4},
   pages = {299-325},
   publisher = {Taylor and Francis Ltd.},
   title = {Causal structure learning for travel mode choice using structural restrictions and model averaging algorithm},
   volume = {13},
   year = {2017},
}
@inproceedings{Ma2015,
   abstract = {Reducing car use and promoting public transport in the cross border area of Luxembourg has become a priority for sustainable development of the Greater region. In this study, we analyze daily mobility mode choice behavior of these cross border workers, in particular, focusing on their multimodal mode choices (e.g. park and ride mode choice) and on their trip chaining behavior. A rule-based approach based on Bayesian networks is proposed to capture the non-linear effects of related determinants/constraints on individuals' mode choice behavior. The result shows the propose Bayesian network has a competitive performance compared with classical discrete choice models with reasonable good corrected prediction rates.},
   author = {Tai Yu Ma},
   doi = {10.1016/j.trpro.2015.09.040},
   issn = {23521465},
   journal = {Transportation Research Procedia},
   keywords = {Luxembourg,bayesian network,mode choice,multimodal,uncertainty},
   pages = {870-880},
   publisher = {Elsevier B.V.},
   title = {Bayesian networks for multimodal mode choice behavior modelling: A case study for the cross border workers of Luxembourg},
   volume = {10},
   year = {2015},
}
@article{Janssens2006,
   abstract = {Several activity-based transportation models are now becoming operational and are entering the stage of application for the modelling of travel demand. Some of these models use decision rules to support its decision-making instead of principles of utility maximization. Decision rules can be derived from different modelling approaches. In a previous study, it was shown that Bayesian networks outperform decision trees and that they are better suited to capture the complexity of the underlying decision-making. However, one of the disadvantages is that Bayesian networks are somewhat limited in terms of interpretation and efficiency when rules are derived from the network, while rules derived from decision trees in general have a simple and direct interpretation. Therefore, in this study, the idea of combining decision trees and Bayesian networks was explored in order to maintain the potential advantages of both techniques. The paper reports the findings of a methodological study that was conducted in the context of Albatross, which is a sequential rule based model of activity scheduling behaviour. To this end, the paper can be situated within the context of a series of previous publications by the authors to improve decision-making in Albatross. The results of this study suggest that integrated Bayesian networks and decision trees can be used for modelling the different choice facets of Albatross with better predictive power than CHAID decision trees. Another conclusion is that there are initial indications that the new way of integrating decision trees and Bayesian networks has produced a decision tree that is structurally more stable. © 2005 Elsevier B.V. All rights reserved.},
   author = {Davy Janssens and Geert Wets and Tom Brijs and Koen Vanhoof and Theo Arentze and Harry Timmermans},
   doi = {10.1016/j.ejor.2005.03.022},
   issn = {03772217},
   issue = {1},
   journal = {European Journal of Operational Research},
   keywords = {Activity-based transportation modelling,BNT classifier,Bayesian networks,Decision trees,Transportation},
   month = {11},
   pages = {16-34},
   title = {Integrating Bayesian networks and decision trees in a sequential rule-based transportation model},
   volume = {175},
   year = {2006},
}
